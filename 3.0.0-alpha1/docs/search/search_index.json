{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"PMD Core Ontology (PMDco) Welcome to the Platform MaterialDigital Core Ontology (PMDco) , your gateway to advancing the digital transformation of Materials Science and Engineering (MSE)! As the field evolves, managing complex workflows, integrating diverse datasets, and achieving interoperability are more critical than ever. PMDco provides a standardized framework to address these challenges, enabling seamless data modeling, enhanced collaboration, and reproducibility across the MSE domain. This documentation is designed to guide you through the ontology's structure, features, and applications, making it easier to incorporate PMDco into your workflows. Whether you're a researcher, developer, or industry professional, we're excited to support your journey toward smarter, more efficient materials science practices. Prefix and namespace Namespace: https://w3id.org/pmd/co Prefix: pmdco Important links The latest version of the ontology can always be found at: pmdco.owl Beginers Guide Miro Board Widoco generated List of Classes and Properties Patterns and Active Development Miro Board (Playground) Citation Please cite the ontology as follows: PMDco: Platform Material Digital Ontology. Version 3.0.0, https://w3id.org/pmd/co/ When referring the PMDco 3.0.0 in publications, please also consider to cite the following publication about version 2.0.8, which provides comprehensive details and the foundational rationale behind the development of this ontology: B. Bayerlein, M. Schilling, H. Birkholz, M. Jung, J. Waitelonis, L. M\u00e4dler, H. Sack, Materials & Design 2024, 237 112603. Bibtex: @article{PMDco2024, title = {{PMD} {C}ore {O}ntology: {A}chieving semantic interoperability in materials science}, journal = {Materials \\& Design}, volume = {237}, pages = {112603}, year = {2024}, issn = {0264-1275}, doi = {https://doi.org/10.1016/j.matdes.2023.112603}, author = {Bayerlein, Bernd and Schilling, Markus and Birkholz, Henk and Jung, Matthias and Waitelonis, J{\\\"o}rg and M{\\\"a}dler, Lutz and Sack, Harald} } available at: Materials & Design .","title":"Welcome"},{"location":"#pmd-core-ontology-pmdco","text":"Welcome to the Platform MaterialDigital Core Ontology (PMDco) , your gateway to advancing the digital transformation of Materials Science and Engineering (MSE)! As the field evolves, managing complex workflows, integrating diverse datasets, and achieving interoperability are more critical than ever. PMDco provides a standardized framework to address these challenges, enabling seamless data modeling, enhanced collaboration, and reproducibility across the MSE domain. This documentation is designed to guide you through the ontology's structure, features, and applications, making it easier to incorporate PMDco into your workflows. Whether you're a researcher, developer, or industry professional, we're excited to support your journey toward smarter, more efficient materials science practices.","title":"PMD Core Ontology (PMDco)"},{"location":"#prefix-and-namespace","text":"Namespace: https://w3id.org/pmd/co Prefix: pmdco","title":"Prefix and namespace"},{"location":"#important-links","text":"The latest version of the ontology can always be found at: pmdco.owl Beginers Guide Miro Board Widoco generated List of Classes and Properties Patterns and Active Development Miro Board (Playground)","title":"Important links"},{"location":"#citation","text":"Please cite the ontology as follows: PMDco: Platform Material Digital Ontology. Version 3.0.0, https://w3id.org/pmd/co/ When referring the PMDco 3.0.0 in publications, please also consider to cite the following publication about version 2.0.8, which provides comprehensive details and the foundational rationale behind the development of this ontology: B. Bayerlein, M. Schilling, H. Birkholz, M. Jung, J. Waitelonis, L. M\u00e4dler, H. Sack, Materials & Design 2024, 237 112603. Bibtex: @article{PMDco2024, title = {{PMD} {C}ore {O}ntology: {A}chieving semantic interoperability in materials science}, journal = {Materials \\& Design}, volume = {237}, pages = {112603}, year = {2024}, issn = {0264-1275}, doi = {https://doi.org/10.1016/j.matdes.2023.112603}, author = {Bayerlein, Bernd and Schilling, Markus and Birkholz, Henk and Jung, Matthias and Waitelonis, J{\\\"o}rg and M{\\\"a}dler, Lutz and Sack, Harald} } available at: Materials & Design .","title":"Citation"},{"location":"acknowledgements/","text":"The authors thank the Federal Government and the Heads of Government of the L\u00e4nder for their funding and support within the framework of the Plattform MaterialDigital . Funded by the german Federal Ministry of Education and Research (BMBF) through project funding no. 13XP5094.","title":"Acknowledgements"},{"location":"background_and_context/","text":"Background and Context Domain Overview The Platform MaterialDigital Core Ontology (PMDco) addresses challenges in the domain of Materials Science and Engineering (MSE), which is subject to significant digital transformation. The MSE domain is an interdisciplinary field that focuses on understanding and adaption of material properties to develop new and improve existing products. The MSE domain combines principles from physics, chemistry, and engineering to explore the relationships between the structure, properties, processing, and performance of materials. In summary, key components of the MSE domain can be categorized in: Materials Classes , such as metals, ceramics, polymer, composites, etc., Applications and Research Areas , which include, e.g., nanotechnology, metallurgy, or materials testing, and Materials Related Paradigms , which are summarized by processing, structure, properties, and performance (PSPP). Materials Paradigms Processing : The methods used to shape and treat materials to achieve desired properties. This includes techniques like casting, forging, and additive manufacturing. Structure : The arrangement of atoms and molecules within a material, which can be observed at different scales (atomic, microscopic, and macroscopic). Properties : The characteristics of materials that determine their behavior under various conditions. These include mechanical, electrical, thermal, optical, and magnetic properties. Performance : How well a material performs in a specific application, considering factors like durability, efficiency, and cost-effectiveness. MSE is crucial for technological advancement and innovation. It drives the development of new materials that can lead to breakthroughs in various industries, including aerospace, automotive, electronics, healthcare, and energy. By understanding and controlling the properties of materials, scientists and engineers can create solutions that improve performance, efficiency, and sustainability. Especially with regard to the latter, MSE encompasses the entire materials lifecycle, from raw material procurement to the development of components, production, and end-of-life recycling. As a matter of fact, efficient data management in MSE is vital for enhancing productivity, enabling innovations, and ensuring sustainability. This requires harmonized data structures that are accessible, reusable, and interoperable. Semantic interoperability, enabled by ontologies, bridges the gap between high-level conceptual frameworks and specific domain applications, making it easier to capture, share, and reuse data across disciplines and throughout material lifecycles. Motivation The creation of the PMDco is driven by the need to overcome critical data integration and management challenges in MSE, such as: Heterogeneity of Terminology : MSE involves diverse perspectives from its subdomains, leading to inconsistencies in terminology that hinder data sharing and understanding. Lack of Standardized Data Formats : Data from experiments, simulations, and industrial processes often lack uniform structure, impeding the seamless exchange of information. Sparse and Incomplete Data : Contextual information, including metadata and provenance, is frequently missing, limiting reproducibility and reuse. Semantic Gaps Between Domains : The absence of alignment between high-level and domain-specific vocabularies poses integration challenges for cross-disciplinary research. The PMDco serves as a mid-level ontology designed to address these challenges by standardizing the MSE terminologies and processes, enabling automated data integration, and facilitating adherence to the FAIR (Findable, Accessible, Interoperable, Reusable) principles. Reusing Existing Ontologies The PMDco complements and extends several existing ontologies by providing a mid-level framework tailored for the MSE domain. The top-level ontology we use is: The Basic Formal Ontology which is an ISO standard BFO2020 for the top-level ontologies and provides abstract, cross-domain semantic structures. However, its highly abstract nature complicates direct application to MSE-specific contexts. PMDco bridges the gap by integrating MSE-specific concepts into this general framework. Some parts of the following ontologies are imported into PMDco: Chemical Entities of Biological Interest ( ChEBI ) facilitates representation of chemical entities. Information Artifact Ontology ( IAO ) represents types of information content entities such as documents, databases, and digital images. Ontology for Biomedical Investigations ( OBI ) is actually a collection of ontologies, which helps to communicate about scientific investigations by defining terms for assays, devices, objectives, and more. Please note that while IAO and OBI ontologies are not the domain-level ontologies in the usual meaning, we put them into this list to point out that they cover only certain \"aspects of reality\", in contrast to the BFO ontology, aiming to provide a comprehensive abstract framework for all the concepts. Despite their utility, many existing ontologies are niche-focused, inaccessible, or poorly maintained, limiting their broader applicability. The PMDco incorporates reusable components from these ontologies while addressing their limitations through a community-driven development and curation process.","title":"Background and Context"},{"location":"background_and_context/#background-and-context","text":"","title":"Background and Context"},{"location":"background_and_context/#domain-overview","text":"The Platform MaterialDigital Core Ontology (PMDco) addresses challenges in the domain of Materials Science and Engineering (MSE), which is subject to significant digital transformation. The MSE domain is an interdisciplinary field that focuses on understanding and adaption of material properties to develop new and improve existing products. The MSE domain combines principles from physics, chemistry, and engineering to explore the relationships between the structure, properties, processing, and performance of materials. In summary, key components of the MSE domain can be categorized in: Materials Classes , such as metals, ceramics, polymer, composites, etc., Applications and Research Areas , which include, e.g., nanotechnology, metallurgy, or materials testing, and Materials Related Paradigms , which are summarized by processing, structure, properties, and performance (PSPP). Materials Paradigms Processing : The methods used to shape and treat materials to achieve desired properties. This includes techniques like casting, forging, and additive manufacturing. Structure : The arrangement of atoms and molecules within a material, which can be observed at different scales (atomic, microscopic, and macroscopic). Properties : The characteristics of materials that determine their behavior under various conditions. These include mechanical, electrical, thermal, optical, and magnetic properties. Performance : How well a material performs in a specific application, considering factors like durability, efficiency, and cost-effectiveness. MSE is crucial for technological advancement and innovation. It drives the development of new materials that can lead to breakthroughs in various industries, including aerospace, automotive, electronics, healthcare, and energy. By understanding and controlling the properties of materials, scientists and engineers can create solutions that improve performance, efficiency, and sustainability. Especially with regard to the latter, MSE encompasses the entire materials lifecycle, from raw material procurement to the development of components, production, and end-of-life recycling. As a matter of fact, efficient data management in MSE is vital for enhancing productivity, enabling innovations, and ensuring sustainability. This requires harmonized data structures that are accessible, reusable, and interoperable. Semantic interoperability, enabled by ontologies, bridges the gap between high-level conceptual frameworks and specific domain applications, making it easier to capture, share, and reuse data across disciplines and throughout material lifecycles.","title":"Domain Overview"},{"location":"background_and_context/#motivation","text":"The creation of the PMDco is driven by the need to overcome critical data integration and management challenges in MSE, such as: Heterogeneity of Terminology : MSE involves diverse perspectives from its subdomains, leading to inconsistencies in terminology that hinder data sharing and understanding. Lack of Standardized Data Formats : Data from experiments, simulations, and industrial processes often lack uniform structure, impeding the seamless exchange of information. Sparse and Incomplete Data : Contextual information, including metadata and provenance, is frequently missing, limiting reproducibility and reuse. Semantic Gaps Between Domains : The absence of alignment between high-level and domain-specific vocabularies poses integration challenges for cross-disciplinary research. The PMDco serves as a mid-level ontology designed to address these challenges by standardizing the MSE terminologies and processes, enabling automated data integration, and facilitating adherence to the FAIR (Findable, Accessible, Interoperable, Reusable) principles.","title":"Motivation"},{"location":"background_and_context/#reusing-existing-ontologies","text":"The PMDco complements and extends several existing ontologies by providing a mid-level framework tailored for the MSE domain. The top-level ontology we use is: The Basic Formal Ontology which is an ISO standard BFO2020 for the top-level ontologies and provides abstract, cross-domain semantic structures. However, its highly abstract nature complicates direct application to MSE-specific contexts. PMDco bridges the gap by integrating MSE-specific concepts into this general framework. Some parts of the following ontologies are imported into PMDco: Chemical Entities of Biological Interest ( ChEBI ) facilitates representation of chemical entities. Information Artifact Ontology ( IAO ) represents types of information content entities such as documents, databases, and digital images. Ontology for Biomedical Investigations ( OBI ) is actually a collection of ontologies, which helps to communicate about scientific investigations by defining terms for assays, devices, objectives, and more. Please note that while IAO and OBI ontologies are not the domain-level ontologies in the usual meaning, we put them into this list to point out that they cover only certain \"aspects of reality\", in contrast to the BFO ontology, aiming to provide a comprehensive abstract framework for all the concepts. Despite their utility, many existing ontologies are niche-focused, inaccessible, or poorly maintained, limiting their broader applicability. The PMDco incorporates reusable components from these ontologies while addressing their limitations through a community-driven development and curation process.","title":"Reusing Existing Ontologies"},{"location":"contributing/","text":"How to contribute to PMDco Contribute via GitHub issues We use GitHub Issues to streamline and document contributions to our ontology development process. Whether you\u2019re reporting a problem, suggesting improvements, or proposing new concepts, GitHub Issues is the primary platform for collaboration. Here you can find the Issue tracker . How It Works Access the Repository Issue Tracker Visit the Issue tracker of our GitHub repository where the ontology project is hosted. Open a New Issue Click on the \u201cIssues\u201d tab in the repository menu. Select \u201cNew Issue\u201d and provide a clear, descriptive title for your contribution. Provide Detailed Information In the issue body, describe your suggestion or concern in detail. Be specific and include relevant context, such as: Terms/concepts involved. Examples or use cases. References to existing ontology elements, if applicable. If you are reporting a bug or error, include steps to reproduce it. Categorize Your Issue Use available labels (e.g., bug , enhancement , question ) to categorize your issue. This helps others understand its nature at a glance. Engage in Discussion Once submitted, your issue may receive feedback or questions from other contributors or maintainers. Please respond promptly to keep the discussion active and collaborative. Track Progress You can monitor the status of your issue through updates and notifications. GitHub will alert you to any changes or resolutions. Close the Issue Once the issue has been addressed, either the maintainers or you (if appropriate) can close it. Tips for Effective Contributions Be Clear and Concise : Aim for clarity to ensure everyone understands your input. Use Markdown : Format your text using GitHub-flavored Markdown for better readability. Stay Respectful : Maintain a professional tone to foster constructive collaboration. For further questions about using GitHub or contributing to the ontology, don\u2019t hesitate to contact us. We appreciate your contributions and look forward to collaborating with you! Contribute via Ontology Playground The Ontology Playground is a collaborative space and open forum designed for discussion and feedback from experts in the field. It typically takes place online via MS Teams every other Friday. The insights gathered from these sessions play a crucial role in shaping the PMDco curation process. We warmly invite you to participate! To request an invitation, please contact us at https://materialdigital.de/contact/ .","title":"Contributing"},{"location":"contributing/#how-to-contribute-to-pmdco","text":"","title":"How to contribute to PMDco"},{"location":"contributing/#contribute-via-github-issues","text":"We use GitHub Issues to streamline and document contributions to our ontology development process. Whether you\u2019re reporting a problem, suggesting improvements, or proposing new concepts, GitHub Issues is the primary platform for collaboration. Here you can find the Issue tracker .","title":"Contribute via GitHub issues"},{"location":"contributing/#how-it-works","text":"Access the Repository Issue Tracker Visit the Issue tracker of our GitHub repository where the ontology project is hosted. Open a New Issue Click on the \u201cIssues\u201d tab in the repository menu. Select \u201cNew Issue\u201d and provide a clear, descriptive title for your contribution. Provide Detailed Information In the issue body, describe your suggestion or concern in detail. Be specific and include relevant context, such as: Terms/concepts involved. Examples or use cases. References to existing ontology elements, if applicable. If you are reporting a bug or error, include steps to reproduce it. Categorize Your Issue Use available labels (e.g., bug , enhancement , question ) to categorize your issue. This helps others understand its nature at a glance. Engage in Discussion Once submitted, your issue may receive feedback or questions from other contributors or maintainers. Please respond promptly to keep the discussion active and collaborative. Track Progress You can monitor the status of your issue through updates and notifications. GitHub will alert you to any changes or resolutions. Close the Issue Once the issue has been addressed, either the maintainers or you (if appropriate) can close it.","title":"How It Works"},{"location":"contributing/#tips-for-effective-contributions","text":"Be Clear and Concise : Aim for clarity to ensure everyone understands your input. Use Markdown : Format your text using GitHub-flavored Markdown for better readability. Stay Respectful : Maintain a professional tone to foster constructive collaboration. For further questions about using GitHub or contributing to the ontology, don\u2019t hesitate to contact us. We appreciate your contributions and look forward to collaborating with you!","title":"Tips for Effective Contributions"},{"location":"contributing/#contribute-via-ontology-playground","text":"The Ontology Playground is a collaborative space and open forum designed for discussion and feedback from experts in the field. It typically takes place online via MS Teams every other Friday. The insights gathered from these sessions play a crucial role in shaping the PMDco curation process. We warmly invite you to participate! To request an invitation, please contact us at https://materialdigital.de/contact/ .","title":"Contribute via Ontology Playground"},{"location":"design_and_methodology/","text":"Design and Methodology Design Principles The design of the ontology adheres to several fundamental principles to ensure usability, scalability, and alignment with the broader materials science community: Modularity : The ontology is constructed in a modular fashion to enable different components to be developed, maintained, and reused independently. This approach supports scalability and customization for diverse use cases within the field of MSE while maintaining a cohesive structure. Reuse of Existing Standards : Existing ontologies and standards such as IAO and ChEBI have been integrated into the ontology to enhance semantic consistency and avoid duplication of effort. Aligning with these well-established resources ensures interoperability with other knowledge systems. Furthermore, established standards within the MSE realm are used to create, label, and define relevant concepts. One of the advantages is their broad distribution among stakeholders and a terminology and denomination a group of experts in the field has already agreed upon which enhances its acceptability. Community-Driven Development : The ontology is curated and refined through ongoing engagement with domain experts and stakeholders. Workshops, feedback sessions, and collaborative modeling exercises are integral to ensuring the ontology addresses real-world requirements effectively. Adherence to FAIR Principles : The design facilitates the creation of Findable, Accessible, Interoperable, and Reusable (FAIR) datasets by providing well-defined semantics and structured frameworks for data representation. Ontology Language and Tools Ontology Language The ontology is implemented in the Web Ontology Language (OWL) , a powerful and widely used language for creating complex and interoperable ontologies. OWL supports logical reasoning and facilitates the integration of machine-readable data with semantic web technologies. Furthermore, different notations and formats may be used. Typically, PMDco is also provided in Turtle (TTL) syntax. Tools Used Prot\u00e9g\u00e9 : A versatile ontology editor that supports OWL 2. It enables visualization, editing, and reasoning over ontology structures. Prot\u00e9g\u00e9 was used for creating and managing the ontology. OntoPanel : A graphical plug-in for diagrams.net that simplifies ontology development and visualization for domain experts. Python Libraries : Libraries such as rdflib and Owlready2 were employed for semantic data processing, integration, and validation. Version Control and Collaboration : GitHub was used for version control, issue tracking, and collaborative development, ensuring transparency and structured updates. Development Process The ontology development followed a structured and iterative process: Requirements Gathering : Conduct surveys and consultations with domain experts to identify key concepts, relationships, and use cases. In particular, consideration and involvement of standards relevant in the field of MSE. Analyze existing data and workflows in MSE to understand integration points and challenges. Conceptual Modeling : Develop visual representations of key processes and entities using tools like ConceptBoard or Miro. Structure concepts hierarchically, linking mid-level ontology elements to top-level frameworks (e.g., BFO). Implementation : Define classes, properties, and axioms in OWL using the well-known ontology creation and manipulation tool Prot\u00e9g\u00e9 . Leverage existing ontologies where possible, mapping relevant terms and extending them with domain-specific semantics. Validation and Iteration : Use reasoning tools (e.g., reasoners HermiT and Pellet) to ensure logical and technical consistency and identify potential redundancies. Validate the ontology against real-world datasets and application scenarios through collaborative workshops. Documentation and Training : Create detailed documentation, including best practices, examples, and guidelines for using the ontology. Conduct training sessions for stakeholders to facilitate adoption and feedback collection. Versioning and Updates Version Control The ontology employs a robust versioning system hosted on GitHub, aiming to ensure: Clear tracking of changes over time. Transparent contributions from the community. Accessibility of historical versions for comparison and reference. Update Mechanism Community Feedback Loop : Regular workshops and feedback sessions with MSE experts to identify necessary additions and refinements. Implementation of a curation process to assess and prioritize updates based on community needs. Release Cycle : Major updates may be rolled out to a certain extent, incorporating substantial changes and new features. Minor updates addressing bug fixes or minor refinements are released on a need basis. Documentation of Changes : A comprehensive changelog is maintained for every release, detailing added, modified, or deprecated elements.","title":"Design and Methodology"},{"location":"design_and_methodology/#design-and-methodology","text":"","title":"Design and Methodology"},{"location":"design_and_methodology/#design-principles","text":"The design of the ontology adheres to several fundamental principles to ensure usability, scalability, and alignment with the broader materials science community: Modularity : The ontology is constructed in a modular fashion to enable different components to be developed, maintained, and reused independently. This approach supports scalability and customization for diverse use cases within the field of MSE while maintaining a cohesive structure. Reuse of Existing Standards : Existing ontologies and standards such as IAO and ChEBI have been integrated into the ontology to enhance semantic consistency and avoid duplication of effort. Aligning with these well-established resources ensures interoperability with other knowledge systems. Furthermore, established standards within the MSE realm are used to create, label, and define relevant concepts. One of the advantages is their broad distribution among stakeholders and a terminology and denomination a group of experts in the field has already agreed upon which enhances its acceptability. Community-Driven Development : The ontology is curated and refined through ongoing engagement with domain experts and stakeholders. Workshops, feedback sessions, and collaborative modeling exercises are integral to ensuring the ontology addresses real-world requirements effectively. Adherence to FAIR Principles : The design facilitates the creation of Findable, Accessible, Interoperable, and Reusable (FAIR) datasets by providing well-defined semantics and structured frameworks for data representation.","title":"Design Principles"},{"location":"design_and_methodology/#ontology-language-and-tools","text":"","title":"Ontology Language and Tools"},{"location":"design_and_methodology/#ontology-language","text":"The ontology is implemented in the Web Ontology Language (OWL) , a powerful and widely used language for creating complex and interoperable ontologies. OWL supports logical reasoning and facilitates the integration of machine-readable data with semantic web technologies. Furthermore, different notations and formats may be used. Typically, PMDco is also provided in Turtle (TTL) syntax.","title":"Ontology Language"},{"location":"design_and_methodology/#tools-used","text":"Prot\u00e9g\u00e9 : A versatile ontology editor that supports OWL 2. It enables visualization, editing, and reasoning over ontology structures. Prot\u00e9g\u00e9 was used for creating and managing the ontology. OntoPanel : A graphical plug-in for diagrams.net that simplifies ontology development and visualization for domain experts. Python Libraries : Libraries such as rdflib and Owlready2 were employed for semantic data processing, integration, and validation. Version Control and Collaboration : GitHub was used for version control, issue tracking, and collaborative development, ensuring transparency and structured updates.","title":"Tools Used"},{"location":"design_and_methodology/#development-process","text":"The ontology development followed a structured and iterative process: Requirements Gathering : Conduct surveys and consultations with domain experts to identify key concepts, relationships, and use cases. In particular, consideration and involvement of standards relevant in the field of MSE. Analyze existing data and workflows in MSE to understand integration points and challenges. Conceptual Modeling : Develop visual representations of key processes and entities using tools like ConceptBoard or Miro. Structure concepts hierarchically, linking mid-level ontology elements to top-level frameworks (e.g., BFO). Implementation : Define classes, properties, and axioms in OWL using the well-known ontology creation and manipulation tool Prot\u00e9g\u00e9 . Leverage existing ontologies where possible, mapping relevant terms and extending them with domain-specific semantics. Validation and Iteration : Use reasoning tools (e.g., reasoners HermiT and Pellet) to ensure logical and technical consistency and identify potential redundancies. Validate the ontology against real-world datasets and application scenarios through collaborative workshops. Documentation and Training : Create detailed documentation, including best practices, examples, and guidelines for using the ontology. Conduct training sessions for stakeholders to facilitate adoption and feedback collection.","title":"Development Process"},{"location":"design_and_methodology/#versioning-and-updates","text":"","title":"Versioning and Updates"},{"location":"design_and_methodology/#version-control","text":"The ontology employs a robust versioning system hosted on GitHub, aiming to ensure: Clear tracking of changes over time. Transparent contributions from the community. Accessibility of historical versions for comparison and reference.","title":"Version Control"},{"location":"design_and_methodology/#update-mechanism","text":"Community Feedback Loop : Regular workshops and feedback sessions with MSE experts to identify necessary additions and refinements. Implementation of a curation process to assess and prioritize updates based on community needs. Release Cycle : Major updates may be rolled out to a certain extent, incorporating substantial changes and new features. Minor updates addressing bug fixes or minor refinements are released on a need basis. Documentation of Changes : A comprehensive changelog is maintained for every release, detailing added, modified, or deprecated elements.","title":"Update Mechanism"},{"location":"glossary_and_tools/","text":"Tools and Resources The Ontology Development Kit (ODK) The PMDco development is made with the help of the ontology development kit (ODK). The ODK is an incredibly great tool to manage your ontology's life cycle. The ODK is: a toolbox of various ontology related tools such as ROBOT, owltools, dosdp-tools and many more, bundled as a docker image a set of executable workflows for managing your ontology's continuous integration, quality control, releases and dynamic imports. We thank the ODK team for their outstanding work. Link to the ODK repo. Ontology Development Guide In cooperation with participants in the ( MaterialDigital initiative ), a guide for the development of ontologies in general was created, which contains basic aspects and recommended procedures. This guide may be expanded and developed further and is hosted at the The Scientific Ontology Network. Development Guidelines at The Scientific Ontology Network Get the Guide (Direct Link) Relevant Youtube Channels for Ontology Development related to PMDco PMD YouTube channel ISE FIZ YouTube channel Playlist of Lectures \"Knowledge Graphs - Foundations and Applications\" Barry Smith's YouTube channel Other Initiatives There are a lot of initiatives working on aspects of and respective tools available to facilitate the digitalization in the field of materials science and engineering (MSE), a selection of which is given here. Matportal project NFDI-MatWerk NFDI-MatWerk Teaching Material NFDI Matwerk Video Selection EMMO - The Elementary Multiperspective Material Ontology Tools for Ontology Development and Maintenance Prot\u00e9g\u00e9 - Software used for ontology development and maintenance. ODK Ontology development kit. Draw.io - Online tool for visual diagrams construction. OntoPanel - A tool for ontology creation, including the Draw.io plugin Chowlk Converter - Chowlk Converter is a web application that takes as input an ontology conceptualization made with diagrams.net and generates its implementation in OWL. OTTR - language with supporting tools for representing and instantiating RDF graph and OWL ontology modelling patterns. Provides an abstraction level on top of basic RDF functionality. OOPS! - OOPS! is a web-based tool, independent of any ontology development environment, for detecting potential pitfalls that could lead to modelling errors. RDF Grapher - RDF grapher is a web service for parsing RDF data and visualizing it as a graph. OnToology - A system to automate part of the collaborative ontology development process. Given a repository with an owl file, OnToology will survey it and produce diagrams, a complete documentation and validation based on common pitfalls. ROBOT - ROBOT is a tool for working with Open Biomedical Ontologies. It can be used as a command-line tool or as a library for any language on the Java Virtual Machine. Glossary MaterialDigital Initiative Glossary - a comprehensive glossary for the ontology-related terms. English and German versions available. Other Related References Dublin Core Terms - a set of vocabularies consisting of a set of terms which can be used for describing web resources (video, images, web pages, etc.), as well as physical resources such as books, magazines, proceedings, journals, CDs, etc. Resource Description Framework - a framework for representing information in the Web, defining an abstract syntax (a data model) which serves to link all RDF-based languages and specifications. RDF Schema - a data-modelling vocabulary for RDF data. RDF Schema is an extension of the basic RDF vocabulary. Web Ontology Language - an ontology language for the Semantic Web with formally defined meaning. OWL 2 ontologies provide classes, properties, individuals, and data values and are stored as Semantic Web documents. Simple Knowledge Organization System - a common data model for sharing and linking knowledge organization systems via the Web. XML Schema Definition - a World Wide Web Consortium (W3C) recommendation that defines rules and elements for XML documents.","title":"Glossary and Tools"},{"location":"glossary_and_tools/#tools-and-resources","text":"","title":"Tools and Resources"},{"location":"glossary_and_tools/#the-ontology-development-kit-odk","text":"The PMDco development is made with the help of the ontology development kit (ODK). The ODK is an incredibly great tool to manage your ontology's life cycle. The ODK is: a toolbox of various ontology related tools such as ROBOT, owltools, dosdp-tools and many more, bundled as a docker image a set of executable workflows for managing your ontology's continuous integration, quality control, releases and dynamic imports. We thank the ODK team for their outstanding work. Link to the ODK repo.","title":"The Ontology Development Kit (ODK)"},{"location":"glossary_and_tools/#ontology-development-guide","text":"In cooperation with participants in the ( MaterialDigital initiative ), a guide for the development of ontologies in general was created, which contains basic aspects and recommended procedures. This guide may be expanded and developed further and is hosted at the The Scientific Ontology Network. Development Guidelines at The Scientific Ontology Network Get the Guide (Direct Link)","title":"Ontology Development Guide"},{"location":"glossary_and_tools/#relevant-youtube-channels-for-ontology-development-related-to-pmdco","text":"PMD YouTube channel ISE FIZ YouTube channel Playlist of Lectures \"Knowledge Graphs - Foundations and Applications\" Barry Smith's YouTube channel","title":"Relevant Youtube Channels for Ontology Development related to PMDco"},{"location":"glossary_and_tools/#other-initiatives","text":"There are a lot of initiatives working on aspects of and respective tools available to facilitate the digitalization in the field of materials science and engineering (MSE), a selection of which is given here. Matportal project NFDI-MatWerk NFDI-MatWerk Teaching Material NFDI Matwerk Video Selection EMMO - The Elementary Multiperspective Material Ontology","title":"Other Initiatives"},{"location":"glossary_and_tools/#tools-for-ontology-development-and-maintenance","text":"Prot\u00e9g\u00e9 - Software used for ontology development and maintenance. ODK Ontology development kit. Draw.io - Online tool for visual diagrams construction. OntoPanel - A tool for ontology creation, including the Draw.io plugin Chowlk Converter - Chowlk Converter is a web application that takes as input an ontology conceptualization made with diagrams.net and generates its implementation in OWL. OTTR - language with supporting tools for representing and instantiating RDF graph and OWL ontology modelling patterns. Provides an abstraction level on top of basic RDF functionality. OOPS! - OOPS! is a web-based tool, independent of any ontology development environment, for detecting potential pitfalls that could lead to modelling errors. RDF Grapher - RDF grapher is a web service for parsing RDF data and visualizing it as a graph. OnToology - A system to automate part of the collaborative ontology development process. Given a repository with an owl file, OnToology will survey it and produce diagrams, a complete documentation and validation based on common pitfalls. ROBOT - ROBOT is a tool for working with Open Biomedical Ontologies. It can be used as a command-line tool or as a library for any language on the Java Virtual Machine.","title":"Tools for Ontology Development and Maintenance"},{"location":"glossary_and_tools/#glossary","text":"MaterialDigital Initiative Glossary - a comprehensive glossary for the ontology-related terms. English and German versions available.","title":"Glossary"},{"location":"glossary_and_tools/#other-related-references","text":"Dublin Core Terms - a set of vocabularies consisting of a set of terms which can be used for describing web resources (video, images, web pages, etc.), as well as physical resources such as books, magazines, proceedings, journals, CDs, etc. Resource Description Framework - a framework for representing information in the Web, defining an abstract syntax (a data model) which serves to link all RDF-based languages and specifications. RDF Schema - a data-modelling vocabulary for RDF data. RDF Schema is an extension of the basic RDF vocabulary. Web Ontology Language - an ontology language for the Semantic Web with formally defined meaning. OWL 2 ontologies provide classes, properties, individuals, and data values and are stored as Semantic Web documents. Simple Knowledge Organization System - a common data model for sharing and linking knowledge organization systems via the Web. XML Schema Definition - a World Wide Web Consortium (W3C) recommendation that defines rules and elements for XML documents.","title":"Other Related References"},{"location":"intro/","text":"Introduction to the PMD Ontology (PMDco v3.0.x) The Platform MaterialDigital Core Ontology (PMDco) is a mid-level ontology specifically developed to support the digital transformation of the Materials Science and Engineering (MSE) domain. With its latest version (v3.0.x), PMDco integrates a modular approach, aligning with the Basic Formal Ontology (BFO) standard to provide a comprehensive and interoperable framework for modeling materials, processes, and data. Scope The scope of the PMD Ontology (PMDco v3.0.x) is to provide a mid-level semantic framework for Materials Science and Engineering (MSE), enabling consistent representation and integration of materials, processes, and data across MSE related domains. It models workflows like manufacturing, characterization, and data transformation, ensuring traceability and compliance with standards. PMDco supports FAIR principles by promoting interoperable, machine-readable data structures and aligning with established ontologies like BFO, IAO, ChEBI, OBI and QUDT. Its modular design covers key areas such as materials, qualities, devices, and logistics, fostering collaboration and extensibility. The ontology is tailored to meet the evolving needs of MSE research and industry through community-driven development and maintenance. Objectives Semantic Interoperability : Facilitates consistent representation and exchange of materials data across domains and applications by bridging gaps between high-level and domain-specific ontologies. FAIR Data Principles : Supports the Findable, Accessible, Interoperable, and Reusable (FAIR) principles, promoting structured data management and reusability. Workflow Modeling : Provides tools to describe complex MSE workflows, including manufacturing, characterization, and data transformation processes. Key Features Community-Driven Development : Refined collaboratively in the Ontology Playground sessions with input from MSE experts and practitioners. Modular Design : Organized into distinct modules, such as Materials, Manufacturing, Characterization, Data Transformation, Devices, and Logistics, to cover the entire MSE lifecycle. Alignment with Standards : Built on ISO-compliant BFO and integrates with related ontologies like OBI (Ontology for Biomedical Investigations) and IAO (Information Artifact Ontology). Advanced Process Modeling : Enables detailed representation of processes and their substeps, capturing input/output relationships, device roles, and data transformations. Reusability and Extensibility : Incorporates elements from established ontologies such as QUDT (for units and dimensions) and ChEBI (for chemical entities), ensuring broad applicability and cross-domain connectivity. Applications Material Specifications : Models material properties and specifications, ensuring compliance with established standards (e.g., European Steel Grades). Process Chains : Captures the sequence of interconnected processes, such as transforming a steel sheet into test pieces, performing tensile tests, and analyzing resulting data. Data Integration and Analysis : Supports the transformation of raw data (e.g., time series) into derived material properties like elastic modulus, fostering reproducibility and transparency. Device and Function Modeling : Links devices (e.g., forming machines) to their specifications and roles within processes, ensuring traceability and compliance.","title":"Introduction"},{"location":"intro/#introduction-to-the-pmd-ontology-pmdco-v30x","text":"The Platform MaterialDigital Core Ontology (PMDco) is a mid-level ontology specifically developed to support the digital transformation of the Materials Science and Engineering (MSE) domain. With its latest version (v3.0.x), PMDco integrates a modular approach, aligning with the Basic Formal Ontology (BFO) standard to provide a comprehensive and interoperable framework for modeling materials, processes, and data.","title":"Introduction to the PMD Ontology (PMDco v3.0.x)"},{"location":"intro/#scope","text":"The scope of the PMD Ontology (PMDco v3.0.x) is to provide a mid-level semantic framework for Materials Science and Engineering (MSE), enabling consistent representation and integration of materials, processes, and data across MSE related domains. It models workflows like manufacturing, characterization, and data transformation, ensuring traceability and compliance with standards. PMDco supports FAIR principles by promoting interoperable, machine-readable data structures and aligning with established ontologies like BFO, IAO, ChEBI, OBI and QUDT. Its modular design covers key areas such as materials, qualities, devices, and logistics, fostering collaboration and extensibility. The ontology is tailored to meet the evolving needs of MSE research and industry through community-driven development and maintenance.","title":"Scope"},{"location":"intro/#objectives","text":"Semantic Interoperability : Facilitates consistent representation and exchange of materials data across domains and applications by bridging gaps between high-level and domain-specific ontologies. FAIR Data Principles : Supports the Findable, Accessible, Interoperable, and Reusable (FAIR) principles, promoting structured data management and reusability. Workflow Modeling : Provides tools to describe complex MSE workflows, including manufacturing, characterization, and data transformation processes.","title":"Objectives"},{"location":"intro/#key-features","text":"Community-Driven Development : Refined collaboratively in the Ontology Playground sessions with input from MSE experts and practitioners. Modular Design : Organized into distinct modules, such as Materials, Manufacturing, Characterization, Data Transformation, Devices, and Logistics, to cover the entire MSE lifecycle. Alignment with Standards : Built on ISO-compliant BFO and integrates with related ontologies like OBI (Ontology for Biomedical Investigations) and IAO (Information Artifact Ontology). Advanced Process Modeling : Enables detailed representation of processes and their substeps, capturing input/output relationships, device roles, and data transformations. Reusability and Extensibility : Incorporates elements from established ontologies such as QUDT (for units and dimensions) and ChEBI (for chemical entities), ensuring broad applicability and cross-domain connectivity.","title":"Key Features"},{"location":"intro/#applications","text":"Material Specifications : Models material properties and specifications, ensuring compliance with established standards (e.g., European Steel Grades). Process Chains : Captures the sequence of interconnected processes, such as transforming a steel sheet into test pieces, performing tensile tests, and analyzing resulting data. Data Integration and Analysis : Supports the transformation of raw data (e.g., time series) into derived material properties like elastic modulus, fostering reproducibility and transparency. Device and Function Modeling : Links devices (e.g., forming machines) to their specifications and roles within processes, ensuring traceability and compliance.","title":"Applications"},{"location":"ontology_structure/","text":"Ontology Structure BFO as top level ontology The Basic Formal Ontology (BFO) is a top-level ontology that provides a structured framework for organizing entities based on their fundamental nature. It does not include domain-specific content but instead defines high-level categories that support the development of specialized ontologies like NFDIcore. BFO distinguishes entities based on whether they persist through time or unfold over time, dividing them into continuants and occurrents . Continuants (Endurants) Continuants are entities that exist at any given moment in time and maintain their identity over time. There are tree kinds of continuants: independent continuants, generically dependent continuants and specifically dependent continuants. Independent Continuants (IC) These are entities that exist independently and do not require another entity to exist. Material Entities \u2013 Physical objects with spatial extension. Examples : Organisms, buildings, tools. Immaterial Entities \u2013 Boundaries or parts of objects defined by human convention. Examples : The equator, the upper half of a sphere. Generically Dependent Continuants (GDC) These entities depend on independent continuants for their existence. Generically dependent continuants can exist in multiple instances or be replicated across different locations. Examples : A book\u2019s content (as opposed to a single physical copy of the book) A software program (which can be installed on multiple computers) A musical composition (which can be played on different instruments) A dataset and data items Entities with information content Specifically Dependent Continuants (SDC) Specifically dependent continuants are qualities, roles, or dispositions that exist only in relation to a particular independent continuant . They cannot exist independently and must always be inherent in something else . Qualities - Intrinsic properties of an independent continuant. They describe how an entity is at any moment in time. Examples : The color of a leaf, the weight of a person, the temperature of a liquid. Roles - Situational properties that an entity has based on context or social convention . Examples : The role of a teacher, he status of a patient in a hospital, the role of a machine undergoing maintenance. Dispositions and functions - Potential behaviors or tendencies that an entity has, even if they are not currently being realized. Functions are dispositions that represent the particular purpose of something. Examples : The fragility of glass (it might break if dropped), the solubility of salt (it dissolves in water), a person\u2019s ability to speak multiple languages, the function of an oven to heat something up, the function of a screwdriver to turn screws in and out. Occurrents (Perdurants) An occurrents is an entity that unfolds itself in time or it is the start or end of such an entity. Processes Processes are dynamic activities with temporal duration. Examples : A running event, a chemical reaction, cell division. Temporal Regions These represent divisions of time. Examples : A second, an hour, a historical period. Spatiotemporal Regions These combine space and time into a single entity. Examples : The path of a moving object, the trajectory of a planet. Relations in BFO BFO defines formal relationships between entities to maintain consistency. Some key relations include: continunat part of \u2013 Indicates compositional relationships. ( Example: A wheel is part of a car. ) occurent part of - Some process has another process as part. ( Example: A conference event has multiple workshop events. ) located in \u2013 Specifies spatial containment. ( Example: A book is located_in a library. ) bearer of \u2013 Assigns specifically dependent continuants to independent continuants. ( Example: A teacher is the bearer of the educator role. ) has participant - Assigns continuants to processes. ( Example: A student participates a lecture event. ) More information about BFO can be found at the GitHub repo and the documentation page . Key Components of PMDco PMDco follows a classical ontology development approach, incorporating classes, object properties, data properties, individuals, and annotations to define and structure domain knowledge. All elements are categorized in the BFO hierarchy. Classes PMDco defines several primary categories central to materials science and engineering (MSE). These categories provide a structured ontology for representing materials, their properties, processes, and associated devices. The ontology is made of modules, representing categories of the MSE concepts: We provide a few examples from each category below: 1. Materials module : This category includes fundamental entities that represent physical materials, independent of their shape, and their compositional relationships. Examples: bfo:material entity \u2013 the main superclass for materials and objects from BFO. chebi:chemical entity - contains all the periodic elements imported from CHEBI ontology. pmd:Connected Material Entity Aggregate \u2013 A mereological sum of separate material entities, which adhere to one another through chemical bonds or physical junctions that go beyond gravity. Examples: the atoms of a molecule, the molecules forming the membrane of a cell, the epidermis in a human body. pmd:Disonnected Material Entity Aggregate \u2013 A mereological sum of scattered (i.e. spatially separated) material entities, which do not adhere to one another through chemical bonds or physical junctions but, instead, relate to one another merely on grounds of metric proximity. The material entities are separated from one another through space or through other material entities that do not belong to the group. Examples: a heap of stones, a colony of honeybees, a group of synapses. pmd:Material \u2013 A Portion Of Matter that may participate in some Manifacturing Process and whose shape is not relevant for its participation in the Manifacuring Process. Some concrete materials definitions: pmd:Metal - A metal is an engineered material representing a class of materials characterized by high electrical and thermal conductivity, ductility, and metallic bonding. pmd:Ceramics - Ceramics are engineered materials described as non-metallic, inorganic materials characterized by high hardness, brittleness, and heat resistance, commonly used in engineering applications. 2. Qualities module : Material qualities define the intrinsic and extrinsic properties of materials that determine their behavior and usability in various applications. Main BFO superclasses: bfo:quality \u2013 A quality is a specifically dependent continuant that, in contrast to roles and dispositions, does not require any further process in order to be realized bfo:realizable entity - A specifically dependent continuant that inheres in continuant entities and are not exhibited in full at every time in which it inheres in an entity or group of entities. The exhibition or actualization of a realizable entity is a particular manifestation, functioning or process that occurs under certain circumstances. Examples from PMD: pmd:Morphologic Quality - A morphological quality is a material entity that represents the characteristics related to the shape, size, and structure of a material's features. pmd:Material Property - A property is a material trait in terms of the kind and magnitude of response to a specific imposed stimulus. Generally, definitions of properties are made independent of material shape and size. Some concrete properties: pmd:Hardness \u2013 A measure of a material\u2019s resistance to deformation or indentation. pmd:Yield Strength \u2013 The stress at which a material transitions from elastic to plastic deformation. 3. Manufacturing module : This category encompasses various processes and devices involved in the transformation of raw materials into finished products or components. The superclass for industrial processes: pmd:Manufacturing Process - A planned process that is driven by the primary intent to transform objectsA manufacturing process is always a transformative process. More specific examples: pmd:Coating \u2013 A manufacturing process that aims to deposit a permanently adhering layer of a material without a form onto a workpiece, whereby the immediate state of the coating material directly before application is essential. pmd:Forming - A manufacturing process that changes the shape of a solid body through plastic deformation while retaining both mass and structural integrity. pmd:Joining - A manufacturing process that enables the continuous bonding or joining of two or more workpieces with a specific, fixed shape or of such workpieces with a shapeless material, whereby the cohesion is created at specific points and reinforced overall. ** 4. Material Characterization**: Material characterization involves methods and devices used to analyze the physical, mechanical, and chemical properties of materials. Main BFO superclass: bfo:process - p is a process means p is an occurrent that has some temporal proper part and for some time t, p has some material entity as participant The superclass for characterization processes: pmd:Assay - A planned process that has the objective to produce information about a material entity (the evaluant) by examining it. (Imported from OBI ontology) More specific examples: pmd:Acoustical Property Analyzing Process - An assay that measures the acoustic properties of materials by analyzing how sound waves interact with the material. This process involves generating sound waves and observing their reflection, transmission, absorption, or scattering to determine properties such as acoustic impedance, absorption coefficient, and sound speed. pmd:Mechanical Property Analyzing Process - An assay that evaluates the mechanical characteristics of materials, such as strength, hardness, elasticity, and tensile properties, often through tests that measure response to forces and loads. pmd:Tensile Testing Process \u2013 A Mechanical Property Analyzing Process that determines a material's response to tensile forces, measuring its tensile strength, elongation, and Young's modulus. 5. Data Transformation module : This category includes processes that involve computational simulations and digital transformations related to material properties and behaviors. Main BFO superclass: bfo:process - p is a process means p is an occurrent that has some temporal proper part and for some time t, p has some material entity as participant Examples: pmd:Computing Process - A planned process that involves the systematic use of computational methods and tools to perform simulations, analyses, or data transformations to achieve specific scientific or engineering goals. pmd:Simulation Process - A Computing Process that models the behavior of a system over time using mathematical or computational techniques. pmd:Monte Carlo Simulation - A Simulation Process that uses random sampling to solve physical and mathematical problems. 6. Devices module : This category includes devices performing certain functions in industrial processes. Main BFO superclass: bfo:object - An object is a material entity which manifests causal unity & is of a type instances of which are maximal relative to the sort of causal unity manifested. Examples: pmd:Device - A physical or virtual entity used to perform a specific function or task, often involving measurement, manipulation, or analysis of materials. pmd:Furnace - An enclosed structure in which heat is produced (as for heating a house or for reducing ore). pmd:Creep Testing Device - A device used to test the creep behavior of materials under constant stress at high temperatures. Properties PMDco includes properties that define relationships and attributes: Object Properties : stimulates : A relation between a stimulating process and material property, where there is some material entity that is bearer of the material property and participates in the stimulating process, and the material property comes to be realized in the course of the stimulating process. interacts with : A relation between participants of a process indicating that some of the participants SDCs are affected during the process due to the interaction of the participants. consists of : A continuant part property that relates Material Entity Aggregates in the direction of smaller length-scale. Data Properties : has specified value : Assigns a specific value to a property, such as a numerical measurement. has unit : Specifies the unit of measurement for a given value. Individuals While PMDco serves as a mid-level ontology and may not define specific instances, it provides a framework for users to instantiate individuals pertinent to their domain. Therefore, it mostly does not contain individuals in its pure form. The only individuals present in the PMDco are the ones belonging to the subclasses of a pmd:Nature Constant class, defined in the Qualities module: pmd:Aggregate State Value - solid, liquid, etc. pmd:Bravias Lattice (3D) - cubic body-centered, monoclinic primitive, etc. pmd:Metallic Grain Structures - austenite, ferrite, etc. Hierarchy PMDco presents a structured taxonomy with parent-child relationships among classes (class/subclass-relations). This hierarchical structure facilitates organized data representation and promotes interoperability across MSE domains. Some Examples visualized in Protege provided below. Characterization processes taxonomy: Materials taxonomy: Taxonomy of material properties: Taxonomy of physical processes: Annotations PMDco employs annotations to enrich classes and properties with metadata and human readable information, enhancing clarity and usability. This information may be provided in different natural languages (e.g., English and German). Labels | rdfs:label : Provide human-readable names for ontology elements. Comments | rdfs:comment : Offer detailed descriptions, usage notes, clarifications of definitions, or additional relevant information. They may enhance the understanding of the terms regarded. Definitions | skos:definition : Delivers formal, human readable explanations and descriptions of classes and properties. Preferably, Aristotelian definitions are used that support in finding subclass relationships. Definition Source | obo:IAO_0000119 : If the definition was obtained from a specific source (e.g., a well-known work from the field of MSE, a dictionary, or a URI/URL), this is specified as definition source, also citing the original document. Example Annotations : The class Material has the following annotations: rdfs:label: \"Material\"@en rdfs:label: \"Material\"@de rdfs:comment: \"Instances of Portions Of Matter whose shape is relevant for their dispostion to participate in a Manufacturing Process may be SemiFinishedProdcuts.\" skos:definition: \"A Material is a Portion Of Matter that has the disposition to participate in some Manifacturing Process and whose shape is not relevant for its disposition to participate in the Manifacuring Process.\" obo:IAO_0000119: \"Defined in accordance with standard materials science literature.\" rdfs:isDefinedBy: https://w3id.org/pmd/co/ Protege look: Similarly, the object property exists at has the following annotations: rdfs:label: \"exists at\" rdfs:comment: \"Indicates the spatial or temporal existence of an entity.\" skos:definition: \"(Elucidation) exists at is a relation between a particular and some temporal region at which the particular exists\" dc:identifier: \"118-BFO\u201d rdfs:isDefinedBy: https://w3id.org/pmd/co/ skos:example: \"First World War exists at 1914-1916; Mexico exists at January 1, 2000\" Protege look: Aristotelian definition: For providing the class definitions in PMDcore ontology we follow the Aristotelian principle: An Aristotelian definition typically refers to defining something by its genus (general category) and differentia (specific characteristics that distinguish it from other members of the same genus), that should be expressed in the concepts defined in the ontology. This method is rooted in Aristotle's philosophy and is often used in ontology development to define classes in relation to their superclasses. For more information, please see Aristotelian and Aristotelianism . For instance, the class Material may have the following annotations: - Label : \"Material\"@en, \"Material\"@de - Definition : \"A Material is a Portion Of Matter that has the disposition to participate in some Manifacturing Process and whose shape is not relevant for its disposition to participate in the Manifacuring Process.\"@en - Comment : \"The sum of portions of matter of the same type form a portion of matter of that type.\"@en Constraints and Rules PMDco defines specific constraints to ensure data consistency: Cardinality Constraints : Specify the number of times a property can be associated with a class. For example, a Manufacturing Process may be constrained to have some material entity as input using the has_specified_input property. Domain and Range Specifications : Define the applicable classes for properties. The stimulates property (subproperty of realizes ) has a domain of Stimulating Process and a range of Material Property . These constraints ensure logical consistency and facilitate accurate data representation within the ontology.","title":"Ontology Structure"},{"location":"ontology_structure/#ontology-structure","text":"","title":"Ontology Structure"},{"location":"ontology_structure/#bfo-as-top-level-ontology","text":"The Basic Formal Ontology (BFO) is a top-level ontology that provides a structured framework for organizing entities based on their fundamental nature. It does not include domain-specific content but instead defines high-level categories that support the development of specialized ontologies like NFDIcore. BFO distinguishes entities based on whether they persist through time or unfold over time, dividing them into continuants and occurrents .","title":"BFO as top level ontology"},{"location":"ontology_structure/#continuants-endurants","text":"Continuants are entities that exist at any given moment in time and maintain their identity over time. There are tree kinds of continuants: independent continuants, generically dependent continuants and specifically dependent continuants.","title":"Continuants (Endurants)"},{"location":"ontology_structure/#independent-continuants-ic","text":"These are entities that exist independently and do not require another entity to exist. Material Entities \u2013 Physical objects with spatial extension. Examples : Organisms, buildings, tools. Immaterial Entities \u2013 Boundaries or parts of objects defined by human convention. Examples : The equator, the upper half of a sphere.","title":"Independent Continuants (IC)"},{"location":"ontology_structure/#generically-dependent-continuants-gdc","text":"These entities depend on independent continuants for their existence. Generically dependent continuants can exist in multiple instances or be replicated across different locations. Examples : A book\u2019s content (as opposed to a single physical copy of the book) A software program (which can be installed on multiple computers) A musical composition (which can be played on different instruments) A dataset and data items Entities with information content","title":"Generically Dependent Continuants (GDC)"},{"location":"ontology_structure/#specifically-dependent-continuants-sdc","text":"Specifically dependent continuants are qualities, roles, or dispositions that exist only in relation to a particular independent continuant . They cannot exist independently and must always be inherent in something else . Qualities - Intrinsic properties of an independent continuant. They describe how an entity is at any moment in time. Examples : The color of a leaf, the weight of a person, the temperature of a liquid. Roles - Situational properties that an entity has based on context or social convention . Examples : The role of a teacher, he status of a patient in a hospital, the role of a machine undergoing maintenance. Dispositions and functions - Potential behaviors or tendencies that an entity has, even if they are not currently being realized. Functions are dispositions that represent the particular purpose of something. Examples : The fragility of glass (it might break if dropped), the solubility of salt (it dissolves in water), a person\u2019s ability to speak multiple languages, the function of an oven to heat something up, the function of a screwdriver to turn screws in and out.","title":"Specifically Dependent Continuants (SDC)"},{"location":"ontology_structure/#occurrents-perdurants","text":"An occurrents is an entity that unfolds itself in time or it is the start or end of such an entity.","title":"Occurrents (Perdurants)"},{"location":"ontology_structure/#processes","text":"Processes are dynamic activities with temporal duration. Examples : A running event, a chemical reaction, cell division.","title":"Processes"},{"location":"ontology_structure/#temporal-regions","text":"These represent divisions of time. Examples : A second, an hour, a historical period.","title":"Temporal Regions"},{"location":"ontology_structure/#spatiotemporal-regions","text":"These combine space and time into a single entity. Examples : The path of a moving object, the trajectory of a planet.","title":"Spatiotemporal Regions"},{"location":"ontology_structure/#relations-in-bfo","text":"BFO defines formal relationships between entities to maintain consistency. Some key relations include: continunat part of \u2013 Indicates compositional relationships. ( Example: A wheel is part of a car. ) occurent part of - Some process has another process as part. ( Example: A conference event has multiple workshop events. ) located in \u2013 Specifies spatial containment. ( Example: A book is located_in a library. ) bearer of \u2013 Assigns specifically dependent continuants to independent continuants. ( Example: A teacher is the bearer of the educator role. ) has participant - Assigns continuants to processes. ( Example: A student participates a lecture event. ) More information about BFO can be found at the GitHub repo and the documentation page .","title":"Relations in BFO"},{"location":"ontology_structure/#key-components-of-pmdco","text":"PMDco follows a classical ontology development approach, incorporating classes, object properties, data properties, individuals, and annotations to define and structure domain knowledge. All elements are categorized in the BFO hierarchy.","title":"Key Components of PMDco"},{"location":"ontology_structure/#classes","text":"PMDco defines several primary categories central to materials science and engineering (MSE). These categories provide a structured ontology for representing materials, their properties, processes, and associated devices. The ontology is made of modules, representing categories of the MSE concepts: We provide a few examples from each category below: 1. Materials module : This category includes fundamental entities that represent physical materials, independent of their shape, and their compositional relationships. Examples: bfo:material entity \u2013 the main superclass for materials and objects from BFO. chebi:chemical entity - contains all the periodic elements imported from CHEBI ontology. pmd:Connected Material Entity Aggregate \u2013 A mereological sum of separate material entities, which adhere to one another through chemical bonds or physical junctions that go beyond gravity. Examples: the atoms of a molecule, the molecules forming the membrane of a cell, the epidermis in a human body. pmd:Disonnected Material Entity Aggregate \u2013 A mereological sum of scattered (i.e. spatially separated) material entities, which do not adhere to one another through chemical bonds or physical junctions but, instead, relate to one another merely on grounds of metric proximity. The material entities are separated from one another through space or through other material entities that do not belong to the group. Examples: a heap of stones, a colony of honeybees, a group of synapses. pmd:Material \u2013 A Portion Of Matter that may participate in some Manifacturing Process and whose shape is not relevant for its participation in the Manifacuring Process. Some concrete materials definitions: pmd:Metal - A metal is an engineered material representing a class of materials characterized by high electrical and thermal conductivity, ductility, and metallic bonding. pmd:Ceramics - Ceramics are engineered materials described as non-metallic, inorganic materials characterized by high hardness, brittleness, and heat resistance, commonly used in engineering applications. 2. Qualities module : Material qualities define the intrinsic and extrinsic properties of materials that determine their behavior and usability in various applications. Main BFO superclasses: bfo:quality \u2013 A quality is a specifically dependent continuant that, in contrast to roles and dispositions, does not require any further process in order to be realized bfo:realizable entity - A specifically dependent continuant that inheres in continuant entities and are not exhibited in full at every time in which it inheres in an entity or group of entities. The exhibition or actualization of a realizable entity is a particular manifestation, functioning or process that occurs under certain circumstances. Examples from PMD: pmd:Morphologic Quality - A morphological quality is a material entity that represents the characteristics related to the shape, size, and structure of a material's features. pmd:Material Property - A property is a material trait in terms of the kind and magnitude of response to a specific imposed stimulus. Generally, definitions of properties are made independent of material shape and size. Some concrete properties: pmd:Hardness \u2013 A measure of a material\u2019s resistance to deformation or indentation. pmd:Yield Strength \u2013 The stress at which a material transitions from elastic to plastic deformation. 3. Manufacturing module : This category encompasses various processes and devices involved in the transformation of raw materials into finished products or components. The superclass for industrial processes: pmd:Manufacturing Process - A planned process that is driven by the primary intent to transform objectsA manufacturing process is always a transformative process. More specific examples: pmd:Coating \u2013 A manufacturing process that aims to deposit a permanently adhering layer of a material without a form onto a workpiece, whereby the immediate state of the coating material directly before application is essential. pmd:Forming - A manufacturing process that changes the shape of a solid body through plastic deformation while retaining both mass and structural integrity. pmd:Joining - A manufacturing process that enables the continuous bonding or joining of two or more workpieces with a specific, fixed shape or of such workpieces with a shapeless material, whereby the cohesion is created at specific points and reinforced overall. ** 4. Material Characterization**: Material characterization involves methods and devices used to analyze the physical, mechanical, and chemical properties of materials. Main BFO superclass: bfo:process - p is a process means p is an occurrent that has some temporal proper part and for some time t, p has some material entity as participant The superclass for characterization processes: pmd:Assay - A planned process that has the objective to produce information about a material entity (the evaluant) by examining it. (Imported from OBI ontology) More specific examples: pmd:Acoustical Property Analyzing Process - An assay that measures the acoustic properties of materials by analyzing how sound waves interact with the material. This process involves generating sound waves and observing their reflection, transmission, absorption, or scattering to determine properties such as acoustic impedance, absorption coefficient, and sound speed. pmd:Mechanical Property Analyzing Process - An assay that evaluates the mechanical characteristics of materials, such as strength, hardness, elasticity, and tensile properties, often through tests that measure response to forces and loads. pmd:Tensile Testing Process \u2013 A Mechanical Property Analyzing Process that determines a material's response to tensile forces, measuring its tensile strength, elongation, and Young's modulus. 5. Data Transformation module : This category includes processes that involve computational simulations and digital transformations related to material properties and behaviors. Main BFO superclass: bfo:process - p is a process means p is an occurrent that has some temporal proper part and for some time t, p has some material entity as participant Examples: pmd:Computing Process - A planned process that involves the systematic use of computational methods and tools to perform simulations, analyses, or data transformations to achieve specific scientific or engineering goals. pmd:Simulation Process - A Computing Process that models the behavior of a system over time using mathematical or computational techniques. pmd:Monte Carlo Simulation - A Simulation Process that uses random sampling to solve physical and mathematical problems. 6. Devices module : This category includes devices performing certain functions in industrial processes. Main BFO superclass: bfo:object - An object is a material entity which manifests causal unity & is of a type instances of which are maximal relative to the sort of causal unity manifested. Examples: pmd:Device - A physical or virtual entity used to perform a specific function or task, often involving measurement, manipulation, or analysis of materials. pmd:Furnace - An enclosed structure in which heat is produced (as for heating a house or for reducing ore). pmd:Creep Testing Device - A device used to test the creep behavior of materials under constant stress at high temperatures.","title":"Classes"},{"location":"ontology_structure/#properties","text":"PMDco includes properties that define relationships and attributes: Object Properties : stimulates : A relation between a stimulating process and material property, where there is some material entity that is bearer of the material property and participates in the stimulating process, and the material property comes to be realized in the course of the stimulating process. interacts with : A relation between participants of a process indicating that some of the participants SDCs are affected during the process due to the interaction of the participants. consists of : A continuant part property that relates Material Entity Aggregates in the direction of smaller length-scale. Data Properties : has specified value : Assigns a specific value to a property, such as a numerical measurement. has unit : Specifies the unit of measurement for a given value.","title":"Properties"},{"location":"ontology_structure/#individuals","text":"While PMDco serves as a mid-level ontology and may not define specific instances, it provides a framework for users to instantiate individuals pertinent to their domain. Therefore, it mostly does not contain individuals in its pure form. The only individuals present in the PMDco are the ones belonging to the subclasses of a pmd:Nature Constant class, defined in the Qualities module: pmd:Aggregate State Value - solid, liquid, etc. pmd:Bravias Lattice (3D) - cubic body-centered, monoclinic primitive, etc. pmd:Metallic Grain Structures - austenite, ferrite, etc.","title":"Individuals"},{"location":"ontology_structure/#hierarchy","text":"PMDco presents a structured taxonomy with parent-child relationships among classes (class/subclass-relations). This hierarchical structure facilitates organized data representation and promotes interoperability across MSE domains. Some Examples visualized in Protege provided below. Characterization processes taxonomy: Materials taxonomy: Taxonomy of material properties: Taxonomy of physical processes:","title":"Hierarchy"},{"location":"ontology_structure/#annotations","text":"PMDco employs annotations to enrich classes and properties with metadata and human readable information, enhancing clarity and usability. This information may be provided in different natural languages (e.g., English and German). Labels | rdfs:label : Provide human-readable names for ontology elements. Comments | rdfs:comment : Offer detailed descriptions, usage notes, clarifications of definitions, or additional relevant information. They may enhance the understanding of the terms regarded. Definitions | skos:definition : Delivers formal, human readable explanations and descriptions of classes and properties. Preferably, Aristotelian definitions are used that support in finding subclass relationships. Definition Source | obo:IAO_0000119 : If the definition was obtained from a specific source (e.g., a well-known work from the field of MSE, a dictionary, or a URI/URL), this is specified as definition source, also citing the original document. Example Annotations : The class Material has the following annotations: rdfs:label: \"Material\"@en rdfs:label: \"Material\"@de rdfs:comment: \"Instances of Portions Of Matter whose shape is relevant for their dispostion to participate in a Manufacturing Process may be SemiFinishedProdcuts.\" skos:definition: \"A Material is a Portion Of Matter that has the disposition to participate in some Manifacturing Process and whose shape is not relevant for its disposition to participate in the Manifacuring Process.\" obo:IAO_0000119: \"Defined in accordance with standard materials science literature.\" rdfs:isDefinedBy: https://w3id.org/pmd/co/ Protege look: Similarly, the object property exists at has the following annotations: rdfs:label: \"exists at\" rdfs:comment: \"Indicates the spatial or temporal existence of an entity.\" skos:definition: \"(Elucidation) exists at is a relation between a particular and some temporal region at which the particular exists\" dc:identifier: \"118-BFO\u201d rdfs:isDefinedBy: https://w3id.org/pmd/co/ skos:example: \"First World War exists at 1914-1916; Mexico exists at January 1, 2000\" Protege look:","title":"Annotations"},{"location":"ontology_structure/#aristotelian-definition","text":"For providing the class definitions in PMDcore ontology we follow the Aristotelian principle: An Aristotelian definition typically refers to defining something by its genus (general category) and differentia (specific characteristics that distinguish it from other members of the same genus), that should be expressed in the concepts defined in the ontology. This method is rooted in Aristotle's philosophy and is often used in ontology development to define classes in relation to their superclasses. For more information, please see Aristotelian and Aristotelianism . For instance, the class Material may have the following annotations: - Label : \"Material\"@en, \"Material\"@de - Definition : \"A Material is a Portion Of Matter that has the disposition to participate in some Manifacturing Process and whose shape is not relevant for its disposition to participate in the Manifacuring Process.\"@en - Comment : \"The sum of portions of matter of the same type form a portion of matter of that type.\"@en","title":"Aristotelian definition:"},{"location":"ontology_structure/#constraints-and-rules","text":"PMDco defines specific constraints to ensure data consistency: Cardinality Constraints : Specify the number of times a property can be associated with a class. For example, a Manufacturing Process may be constrained to have some material entity as input using the has_specified_input property. Domain and Range Specifications : Define the applicable classes for properties. The stimulates property (subproperty of realizes ) has a domain of Stimulating Process and a range of Material Property . These constraints ensure logical consistency and facilitate accurate data representation within the ontology.","title":"Constraints and Rules"},{"location":"patterns/","text":"Usage Patterns In ontology development and usage, usage patterns play a critical role in addressing recurring modeling requirements. These patterns provide standardized, reusable semantic snippets that facilitate consistent representation of relationships between instances and entities. Furthermore, such patterns may be used to create SHACL shapes to include constraints in a knowledge representation. By following usage patterns, ontology users and developers can ensure uniformity, clarity, and reusability in their models. The sections below illustrate how to read and apply these patterns. Each pattern includes its purpose, description, relevant properties, visualization, and example. Table of Contents Hereby we provide an overview of the patterns used in PMDco 3.0.0: - Pattern 1 : Temporal Region - Pattern 2 : Process Chain - Pattern 3 : Process Inputs and Outputs - Pattern 4 : Realizable Entities - Pattern 5 : Qualities - Pattern 6 : Scalar Measurement - Pattern 7 : Scalar Value Specification - Pattern 8 : Categorical Value Specification - Pattern 9 : Material and Device Specification Example Patterns Pattern 1 - Temporal Region Purpose : Specifying the boundaries of a process on the time axis. Core Properties : bfo:occupiesTemporalRegion bfo:properTemporalPart bfo:hasFirstInstant bfo:hasLastInstant pmd:endsWith Example Use Case : Specifying certain moments of time when some industiral process started or ended. Pattern 2 - Process Chain Purpose : Represent complex processes, consisting of simultaneous and serial subprocesses. Core Properties : bfo:precedes bfo:hasOccurentPart pmd:startsWith pmd:endsWith Example Use Case : Specifying the structure of commplex manufactirung processes consisting of several stages. Pattern 3 - Process Inputs and Outputs Purpose : Describes how to represent inputs and outputs for planned processes typically involving material entities or information-bearing entities. Core Properties : pmd:hasInput pmd:hasOutput Example Use Case : A planned process with possibility of multiple inputs and outputs, e.g., testing properties of a metallic sample, or transforming a piece of material into another product. Pattern 4 - Realizable Entities Purpose : Represent characteristics of the objects, brought to existence by specific situation. Core Properties : bfo:bearerOf bfo:concretizes bfo:realizes bfo:hasParticipant Example Use Case : Specifying the role of specimen, which material object undertakes during a process. Pattern 5 - Qualities Purpose : Represent inherent characteristics of the objects, having certain scalar values at moments/periods of time. Core Properties : bfo:bearerOf bfo:existAt iao:isAbout pmd:derivesFrom Example Use Case : Specifying that value of hardness of a specimen at certain point of time. Pattern 6 - Scalar Measurement Purpose : Represent measured value of some material characteristic. Core Properties : iao:isQualityMeasuredAs bfo:realizes iao:isAbout pmd:hasInput pmd:hasOutput pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying the measured heat capacity value of a specimen. Pattern 7 - Scalar Value Specification Purpose : Represents scalar physical quantities, combining a numerical value and a unit. Core Properties : obi:hasSpecifiedNumericValue iao:hasMeasurementUnitLabel pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying measurements like length, mass, or time with standard units. Pattern 8 - Categorical Value Specification Purpose : Represents object characteristics, described by belonging to some category. Core Properties : obi:hasSpecifiedValue iao:isQualityMeasuredAs pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying that material belongs to a certain category, e.g., is a polymer. Pattern 9 - Material and Device Specification Purpose : Specify the material, from which the object is made, by stating that it complies with the certain material specification. Or, specifying the device in the same manner. Core Properties : iao:isQualityMeasuredAs iao:isAbout pmd:hasValueSpecification pmd:specifiesValueOf Core Idea : provide a class pmd:MaterialSpecification/pmd:DeviceSpecification as a subclass of iao:InformationContentEntity, to which the material/device object can adhere. Example Use Case : Specifying the material of a steel sheet to be the steel S355J2.","title":"Patterns"},{"location":"patterns/#usage-patterns","text":"In ontology development and usage, usage patterns play a critical role in addressing recurring modeling requirements. These patterns provide standardized, reusable semantic snippets that facilitate consistent representation of relationships between instances and entities. Furthermore, such patterns may be used to create SHACL shapes to include constraints in a knowledge representation. By following usage patterns, ontology users and developers can ensure uniformity, clarity, and reusability in their models. The sections below illustrate how to read and apply these patterns. Each pattern includes its purpose, description, relevant properties, visualization, and example.","title":"Usage Patterns"},{"location":"patterns/#table-of-contents","text":"Hereby we provide an overview of the patterns used in PMDco 3.0.0: - Pattern 1 : Temporal Region - Pattern 2 : Process Chain - Pattern 3 : Process Inputs and Outputs - Pattern 4 : Realizable Entities - Pattern 5 : Qualities - Pattern 6 : Scalar Measurement - Pattern 7 : Scalar Value Specification - Pattern 8 : Categorical Value Specification - Pattern 9 : Material and Device Specification","title":"Table of Contents"},{"location":"patterns/#example-patterns","text":"","title":"Example Patterns"},{"location":"patterns/#pattern-1-temporal-region","text":"Purpose : Specifying the boundaries of a process on the time axis. Core Properties : bfo:occupiesTemporalRegion bfo:properTemporalPart bfo:hasFirstInstant bfo:hasLastInstant pmd:endsWith Example Use Case : Specifying certain moments of time when some industiral process started or ended.","title":"Pattern 1 - Temporal Region"},{"location":"patterns/#pattern-2-process-chain","text":"Purpose : Represent complex processes, consisting of simultaneous and serial subprocesses. Core Properties : bfo:precedes bfo:hasOccurentPart pmd:startsWith pmd:endsWith Example Use Case : Specifying the structure of commplex manufactirung processes consisting of several stages.","title":"Pattern 2 - Process Chain"},{"location":"patterns/#pattern-3-process-inputs-and-outputs","text":"Purpose : Describes how to represent inputs and outputs for planned processes typically involving material entities or information-bearing entities. Core Properties : pmd:hasInput pmd:hasOutput Example Use Case : A planned process with possibility of multiple inputs and outputs, e.g., testing properties of a metallic sample, or transforming a piece of material into another product.","title":"Pattern 3 - Process Inputs and Outputs"},{"location":"patterns/#pattern-4-realizable-entities","text":"Purpose : Represent characteristics of the objects, brought to existence by specific situation. Core Properties : bfo:bearerOf bfo:concretizes bfo:realizes bfo:hasParticipant Example Use Case : Specifying the role of specimen, which material object undertakes during a process.","title":"Pattern 4 - Realizable Entities"},{"location":"patterns/#pattern-5-qualities","text":"Purpose : Represent inherent characteristics of the objects, having certain scalar values at moments/periods of time. Core Properties : bfo:bearerOf bfo:existAt iao:isAbout pmd:derivesFrom Example Use Case : Specifying that value of hardness of a specimen at certain point of time.","title":"Pattern 5 - Qualities"},{"location":"patterns/#pattern-6-scalar-measurement","text":"Purpose : Represent measured value of some material characteristic. Core Properties : iao:isQualityMeasuredAs bfo:realizes iao:isAbout pmd:hasInput pmd:hasOutput pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying the measured heat capacity value of a specimen.","title":"Pattern 6 - Scalar Measurement"},{"location":"patterns/#pattern-7-scalar-value-specification","text":"Purpose : Represents scalar physical quantities, combining a numerical value and a unit. Core Properties : obi:hasSpecifiedNumericValue iao:hasMeasurementUnitLabel pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying measurements like length, mass, or time with standard units.","title":"Pattern 7 - Scalar Value Specification"},{"location":"patterns/#pattern-8-categorical-value-specification","text":"Purpose : Represents object characteristics, described by belonging to some category. Core Properties : obi:hasSpecifiedValue iao:isQualityMeasuredAs pmd:hasValueSpecification pmd:specifiesValueOf Example Use Case : Specifying that material belongs to a certain category, e.g., is a polymer.","title":"Pattern 8 - Categorical Value Specification"},{"location":"patterns/#pattern-9-material-and-device-specification","text":"Purpose : Specify the material, from which the object is made, by stating that it complies with the certain material specification. Or, specifying the device in the same manner. Core Properties : iao:isQualityMeasuredAs iao:isAbout pmd:hasValueSpecification pmd:specifiesValueOf Core Idea : provide a class pmd:MaterialSpecification/pmd:DeviceSpecification as a subclass of iao:InformationContentEntity, to which the material/device object can adhere. Example Use Case : Specifying the material of a steel sheet to be the steel S355J2.","title":"Pattern 9 - Material and Device Specification"},{"location":"publications/","text":"Publications List of PMDco related publications The study focusing on the tensile test ontology (TTO), which semantically represents the mechanical tensile test method and is developed within the project Plattform MaterialDigital (PMD): - Schilling, M., Bayerlein, B., v. Hartrott, P.,Waitelonis, J., Birkholz, H., Portella, P. D. and Skrotzki, B. - FAIR and structured data: A domain ontology aligned with standard-compliant tensile testing (2024) The study on applying Semantic Web technologies to advance Materials Science and Engineering (MSE) through the integration of diverse datasets: - Bayerlein, B., Schilling, M., v. Hartrott, P. and Waitelonis, J. - Semantic integration of diverse data in materials science: Assessing Orowan strengthening (2024) The manuscript describing the accelerated development of an ontology for microscopy in materials science and engineering, leveraging natural language processing (NLP) techniques: - Bayerlein, B., Schilling, M., Curran, M., Campbell, C. E., Dima, A. A., Birkholz, H. and Lau, J. W. - Natural language processing-driven Microscopy Ontology development (2024) The study on linking electronic the laboratory notebooks (ELNs) data to semantic concepts, enriching the stored information and improving interpretability and reusability: - Schilling, M., Bruns, S., Bayerlein, B., Kryeziu, J., Schaarschmidt, J., and Waitelonis, J. - Seamless science: Lifting experimental mechanical testing lab data to an interoperable semantic representation (2024) The article describing advancements in the ongoing digital transformation in materials science and engineering: - Bayerlein, B., Waitelonis, J. Birkholz, H. et al. - Concepts for a semantically accessible materials data space - Overview over specific implementations in materials science (2024)","title":"Publications"},{"location":"publications/#publications","text":"","title":"Publications"},{"location":"publications/#list-of-pmdco-related-publications","text":"The study focusing on the tensile test ontology (TTO), which semantically represents the mechanical tensile test method and is developed within the project Plattform MaterialDigital (PMD): - Schilling, M., Bayerlein, B., v. Hartrott, P.,Waitelonis, J., Birkholz, H., Portella, P. D. and Skrotzki, B. - FAIR and structured data: A domain ontology aligned with standard-compliant tensile testing (2024) The study on applying Semantic Web technologies to advance Materials Science and Engineering (MSE) through the integration of diverse datasets: - Bayerlein, B., Schilling, M., v. Hartrott, P. and Waitelonis, J. - Semantic integration of diverse data in materials science: Assessing Orowan strengthening (2024) The manuscript describing the accelerated development of an ontology for microscopy in materials science and engineering, leveraging natural language processing (NLP) techniques: - Bayerlein, B., Schilling, M., Curran, M., Campbell, C. E., Dima, A. A., Birkholz, H. and Lau, J. W. - Natural language processing-driven Microscopy Ontology development (2024) The study on linking electronic the laboratory notebooks (ELNs) data to semantic concepts, enriching the stored information and improving interpretability and reusability: - Schilling, M., Bruns, S., Bayerlein, B., Kryeziu, J., Schaarschmidt, J., and Waitelonis, J. - Seamless science: Lifting experimental mechanical testing lab data to an interoperable semantic representation (2024) The article describing advancements in the ongoing digital transformation in materials science and engineering: - Bayerlein, B., Waitelonis, J. Birkholz, H. et al. - Concepts for a semantically accessible materials data space - Overview over specific implementations in materials science (2024)","title":"List of PMDco related publications"},{"location":"references/","text":"References Resource Description Framework RDF Schema Web Ontology Language Basic Formal Ontology Quantities, Units, Dimensions and Types Ontology Development Kit","title":"References"},{"location":"references/#references","text":"Resource Description Framework RDF Schema Web Ontology Language Basic Formal Ontology Quantities, Units, Dimensions and Types Ontology Development Kit","title":"References"},{"location":"versions/","text":"Versions Stable release versions The latest version of the ontology can always be found at: pmdco.owl and pmdco.ttl Variants The ontology is shipped in three varaints, each as OWL (*.owl) and Turtle serializations (*.ttl): full: pmdco-full.ttl , pmdco.ttl (default) base: pmdco-base.ttl simple: pmdco-simple.ttl The \"full release\" artefact contains all logical axioms, including inferred subsumptions. All imports and components are merged into the full release artefact to ensure easy version management. The full release represents most closely the actual ontology as it was intended at the time of release, including all its logical implications. The \"base file\" is a specific release flavour. It reflects the intention of the ontology author for the official (publicly released) representation of the ontologies \"base entities\". \"Base entities\" are entities that are defined (\"owned\") by the ontology. The representation includes the intended public metadata (annotations), and classification (subClassOf hierarchy), including any statements where a base entity is the subject. The \"simple\" artefact only contains a simple existential graph of the terms defined in the ontology. This corresponds to the state before logical definitions and imports. For example, the only logical axioms are of the form CL1 subClassOf CL2 or CL1 subClassOf R some CL3 where R is any objectProperty and CLn is a class. The simple variant only contains the essential classes and no imports. The ontology \"main\" file pmdco.ttl contains the full version. Editors' version Editors of this ontology should use the edit versions of the differenet modules. You can find them in the components folder. Editors component files: src/ontology/components From the editing main file all release variants are derived by the build workflows. Editors main file: src/ontology/pmdco-edit.owl","title":"Versions"},{"location":"versions/#versions","text":"","title":"Versions"},{"location":"versions/#stable-release-versions","text":"The latest version of the ontology can always be found at: pmdco.owl and pmdco.ttl","title":"Stable release versions"},{"location":"versions/#variants","text":"The ontology is shipped in three varaints, each as OWL (*.owl) and Turtle serializations (*.ttl): full: pmdco-full.ttl , pmdco.ttl (default) base: pmdco-base.ttl simple: pmdco-simple.ttl The \"full release\" artefact contains all logical axioms, including inferred subsumptions. All imports and components are merged into the full release artefact to ensure easy version management. The full release represents most closely the actual ontology as it was intended at the time of release, including all its logical implications. The \"base file\" is a specific release flavour. It reflects the intention of the ontology author for the official (publicly released) representation of the ontologies \"base entities\". \"Base entities\" are entities that are defined (\"owned\") by the ontology. The representation includes the intended public metadata (annotations), and classification (subClassOf hierarchy), including any statements where a base entity is the subject. The \"simple\" artefact only contains a simple existential graph of the terms defined in the ontology. This corresponds to the state before logical definitions and imports. For example, the only logical axioms are of the form CL1 subClassOf CL2 or CL1 subClassOf R some CL3 where R is any objectProperty and CLn is a class. The simple variant only contains the essential classes and no imports. The ontology \"main\" file pmdco.ttl contains the full version.","title":"Variants"},{"location":"versions/#editors-version","text":"Editors of this ontology should use the edit versions of the differenet modules. You can find them in the components folder. Editors component files: src/ontology/components From the editing main file all release variants are derived by the build workflows. Editors main file: src/ontology/pmdco-edit.owl","title":"Editors' version"},{"location":"odk-workflows/","text":"Default ODK Workflows Daily Editors Workflow Release Workflow Manage your ODK Repository Setting up Docker for ODK Imports management Managing the documentation Managing your Automated Testing","title":"Default ODK Workflows"},{"location":"odk-workflows/#default-odk-workflows","text":"Daily Editors Workflow Release Workflow Manage your ODK Repository Setting up Docker for ODK Imports management Managing the documentation Managing your Automated Testing","title":"Default ODK Workflows"},{"location":"odk-workflows/ContinuousIntegration/","text":"Introduction to Continuous Integration Workflows with ODK Historically, most repos have been using Travis CI for continuous integration testing and building, but due to runtime restrictions, we recently switched a lot of our repos to GitHub actions. You can set up your repo with CI by adding this to your configuration file (src/ontology/pmdco-odk.yaml): ci: - github_actions When updateing your repo , you will notice a new file being added: .github/workflows/qc.yml . This file contains your CI logic, so if you need to change, or add anything, this is the place! Alternatively, if your repo is in GitLab instead of GitHub, you can set up your repo with GitLab CI by adding this to your configuration file (src/ontology/pmdco-odk.yaml): ci: - gitlab-ci This will add a file called .gitlab-ci.yml in the root of your repo.","title":"Introduction to Continuous Integration Workflows with ODK"},{"location":"odk-workflows/ContinuousIntegration/#introduction-to-continuous-integration-workflows-with-odk","text":"Historically, most repos have been using Travis CI for continuous integration testing and building, but due to runtime restrictions, we recently switched a lot of our repos to GitHub actions. You can set up your repo with CI by adding this to your configuration file (src/ontology/pmdco-odk.yaml): ci: - github_actions When updateing your repo , you will notice a new file being added: .github/workflows/qc.yml . This file contains your CI logic, so if you need to change, or add anything, this is the place! Alternatively, if your repo is in GitLab instead of GitHub, you can set up your repo with GitLab CI by adding this to your configuration file (src/ontology/pmdco-odk.yaml): ci: - gitlab-ci This will add a file called .gitlab-ci.yml in the root of your repo.","title":"Introduction to Continuous Integration Workflows with ODK"},{"location":"odk-workflows/EditorsWorkflow/","text":"Editors Workflow The editors workflow is one of the formal workflows to ensure that the ontology is developed correctly according to ontology engineering principles. There are a few different editors workflows: Local editing workflow: Editing the ontology in your local environment by hand, using tools such as Prot\u00e9g\u00e9, ROBOT templates or DOSDP patterns. Completely automated data pipeline (GitHub Actions) DROID workflow This document only covers the first editing workflow, but more will be added in the future Local editing workflow Workflow requirements: git github docker editing tool of choice, e.g. Prot\u00e9g\u00e9, your favourite text editor, etc 1. Create issue Ensure that there is a ticket on your issue tracker that describes the change you are about to make. While this seems optional, this is a very important part of the social contract of building an ontology - no change to the ontology should be performed without a good ticket, describing the motivation and nature of the intended change. 2. Update main branch In your local environment (e.g. your laptop), make sure you are on the main (prev. master ) branch and ensure that you have all the upstream changes, for example: git checkout main git pull 3. Create feature branch Create a new branch. Per convention, we try to use meaningful branch names such as: - issue23removeprocess (where issue 23 is the related issue on GitHub) - issue26addcontributor - release20210101 (for releases) On your command line, this looks like this: git checkout -b issue23removeprocess 4. Perform edit Using your editor of choice, perform the intended edit. For example: Prot\u00e9g\u00e9 Open src/ontology/pmdco-edit.owl in Prot\u00e9g\u00e9 Make the change Save the file TextEdit Open src/ontology/pmdco-edit.owl in TextEdit (or Sublime, Atom, Vim, Nano) Make the change Save the file Consider the following when making the edit. According to our development philosophy, the only places that should be manually edited are: src/ontology/pmdco-edit.owl Any ROBOT templates you chose to use (the TSV files only) Any DOSDP data tables you chose to use (the TSV files, and potentially the associated patterns) components (anything in src/ontology/components ), see here . Imports should not be edited (any edits will be flushed out with the next update). However, refreshing imports is a potentially breaking change - and is discussed elsewhere . Changes should usually be small. Adding or changing 1 term is great. Adding or changing 10 related terms is ok. Adding or changing 100 or more terms at once should be considered very carefully. 4. Check the Git diff This step is very important. Rather than simply trusting your change had the intended effect, we should always use a git diff as a first pass for sanity checking. In our experience, having a visual git client like GitHub Desktop or sourcetree is really helpful for this part. In case you prefer the command line: git status git diff 5. Quality control Now it's time to run your quality control checks. This can either happen locally ( 5a ) or through your continuous integration system ( 7/5b ). 5a. Local testing If you chose to run your test locally: sh run.sh make IMP=false test This will run the whole set of configured ODK tests on including your change. If you have a complex DOSDP pattern pipeline you may want to add PAT=false to skip the potentially lengthy process of rebuilding the patterns. sh run.sh make IMP=false PAT=false test 6. Pull request When you are happy with the changes, you commit your changes to your feature branch, push them upstream (to GitHub) and create a pull request. For example: git add NAMEOFCHANGEDFILES git commit -m \"Added biological process term #12\" git push -u origin issue23removeprocess Then you go to your project on GitHub, and create a new pull request from the branch, for example: https://github.com/INCATools/ontology-development-kit/pulls There is a lot of great advise on how to write pull requests, but at the very least you should: - mention the tickets affected: see #23 to link to a related ticket, or fixes #23 if, by merging this pull request, the ticket is fixed. Tickets in the latter case will be closed automatically by GitHub when the pull request is merged. - summarise the changes in a few sentences. Consider the reviewer: what would they want to know right away. - If the diff is large, provide instructions on how to review the pull request best (sometimes, there are many changed files, but only one important change). 7/5b. Continuous Integration Testing If you didn't run and local quality control checks (see 5a ), you should have Continuous Integration (CI) set up, for example: - Travis - GitHub Actions More on how to set this up here . Once the pull request is created, the CI will automatically trigger. If all is fine, it will show up green, otherwise red. 8. Community review Once all the automatic tests have passed, it is important to put a second set of eyes on the pull request. Ontologies are inherently social - as in that they represent some kind of community consensus on how a domain is organised conceptually. This seems high brow talk, but it is very important that as an ontology editor, you have your work validated by the community you are trying to serve (e.g. your colleagues, other contributors etc.). In our experience, it is hard to get more than one review on a pull request - two is great. You can set up GitHub branch protection to actually require a review before a pull request can be merged! We recommend this. This step seems daunting to some hopefully under-resourced ontologies, but we recommend to put this high up on your list of priorities - train a colleague, reach out! 9. Merge and cleanup When the QC is green and the reviews are in (approvals), it is time to merge the pull request. After the pull request is merged, remember to delete the branch as well (this option will show up as a big button right after you have merged the pull request). If you have not done so, close all the associated tickets fixed by the pull request. 10. Changelog (Optional) It is sometimes difficult to keep track of changes made to an ontology. Some ontology teams opt to document changes in a changelog (simply a text file in your repository) so that when release day comes, you know everything you have changed. This is advisable at least for major changes (such as a new release system, a new pattern or template etc.).","title":"Editors Workflow"},{"location":"odk-workflows/EditorsWorkflow/#editors-workflow","text":"The editors workflow is one of the formal workflows to ensure that the ontology is developed correctly according to ontology engineering principles. There are a few different editors workflows: Local editing workflow: Editing the ontology in your local environment by hand, using tools such as Prot\u00e9g\u00e9, ROBOT templates or DOSDP patterns. Completely automated data pipeline (GitHub Actions) DROID workflow This document only covers the first editing workflow, but more will be added in the future","title":"Editors Workflow"},{"location":"odk-workflows/EditorsWorkflow/#local-editing-workflow","text":"Workflow requirements: git github docker editing tool of choice, e.g. Prot\u00e9g\u00e9, your favourite text editor, etc","title":"Local editing workflow"},{"location":"odk-workflows/EditorsWorkflow/#1-create-issue","text":"Ensure that there is a ticket on your issue tracker that describes the change you are about to make. While this seems optional, this is a very important part of the social contract of building an ontology - no change to the ontology should be performed without a good ticket, describing the motivation and nature of the intended change.","title":"1. Create issue"},{"location":"odk-workflows/EditorsWorkflow/#2-update-main-branch","text":"In your local environment (e.g. your laptop), make sure you are on the main (prev. master ) branch and ensure that you have all the upstream changes, for example: git checkout main git pull","title":"2. Update main branch"},{"location":"odk-workflows/EditorsWorkflow/#3-create-feature-branch","text":"Create a new branch. Per convention, we try to use meaningful branch names such as: - issue23removeprocess (where issue 23 is the related issue on GitHub) - issue26addcontributor - release20210101 (for releases) On your command line, this looks like this: git checkout -b issue23removeprocess","title":"3. Create feature branch"},{"location":"odk-workflows/EditorsWorkflow/#4-perform-edit","text":"Using your editor of choice, perform the intended edit. For example: Prot\u00e9g\u00e9 Open src/ontology/pmdco-edit.owl in Prot\u00e9g\u00e9 Make the change Save the file TextEdit Open src/ontology/pmdco-edit.owl in TextEdit (or Sublime, Atom, Vim, Nano) Make the change Save the file Consider the following when making the edit. According to our development philosophy, the only places that should be manually edited are: src/ontology/pmdco-edit.owl Any ROBOT templates you chose to use (the TSV files only) Any DOSDP data tables you chose to use (the TSV files, and potentially the associated patterns) components (anything in src/ontology/components ), see here . Imports should not be edited (any edits will be flushed out with the next update). However, refreshing imports is a potentially breaking change - and is discussed elsewhere . Changes should usually be small. Adding or changing 1 term is great. Adding or changing 10 related terms is ok. Adding or changing 100 or more terms at once should be considered very carefully.","title":"4. Perform edit"},{"location":"odk-workflows/EditorsWorkflow/#4-check-the-git-diff","text":"This step is very important. Rather than simply trusting your change had the intended effect, we should always use a git diff as a first pass for sanity checking. In our experience, having a visual git client like GitHub Desktop or sourcetree is really helpful for this part. In case you prefer the command line: git status git diff","title":"4. Check the Git diff"},{"location":"odk-workflows/EditorsWorkflow/#5-quality-control","text":"Now it's time to run your quality control checks. This can either happen locally ( 5a ) or through your continuous integration system ( 7/5b ).","title":"5. Quality control"},{"location":"odk-workflows/EditorsWorkflow/#5a-local-testing","text":"If you chose to run your test locally: sh run.sh make IMP=false test This will run the whole set of configured ODK tests on including your change. If you have a complex DOSDP pattern pipeline you may want to add PAT=false to skip the potentially lengthy process of rebuilding the patterns. sh run.sh make IMP=false PAT=false test","title":"5a. Local testing"},{"location":"odk-workflows/EditorsWorkflow/#6-pull-request","text":"When you are happy with the changes, you commit your changes to your feature branch, push them upstream (to GitHub) and create a pull request. For example: git add NAMEOFCHANGEDFILES git commit -m \"Added biological process term #12\" git push -u origin issue23removeprocess Then you go to your project on GitHub, and create a new pull request from the branch, for example: https://github.com/INCATools/ontology-development-kit/pulls There is a lot of great advise on how to write pull requests, but at the very least you should: - mention the tickets affected: see #23 to link to a related ticket, or fixes #23 if, by merging this pull request, the ticket is fixed. Tickets in the latter case will be closed automatically by GitHub when the pull request is merged. - summarise the changes in a few sentences. Consider the reviewer: what would they want to know right away. - If the diff is large, provide instructions on how to review the pull request best (sometimes, there are many changed files, but only one important change).","title":"6. Pull request"},{"location":"odk-workflows/EditorsWorkflow/#75b-continuous-integration-testing","text":"If you didn't run and local quality control checks (see 5a ), you should have Continuous Integration (CI) set up, for example: - Travis - GitHub Actions More on how to set this up here . Once the pull request is created, the CI will automatically trigger. If all is fine, it will show up green, otherwise red.","title":"7/5b. Continuous Integration Testing"},{"location":"odk-workflows/EditorsWorkflow/#8-community-review","text":"Once all the automatic tests have passed, it is important to put a second set of eyes on the pull request. Ontologies are inherently social - as in that they represent some kind of community consensus on how a domain is organised conceptually. This seems high brow talk, but it is very important that as an ontology editor, you have your work validated by the community you are trying to serve (e.g. your colleagues, other contributors etc.). In our experience, it is hard to get more than one review on a pull request - two is great. You can set up GitHub branch protection to actually require a review before a pull request can be merged! We recommend this. This step seems daunting to some hopefully under-resourced ontologies, but we recommend to put this high up on your list of priorities - train a colleague, reach out!","title":"8. Community review"},{"location":"odk-workflows/EditorsWorkflow/#9-merge-and-cleanup","text":"When the QC is green and the reviews are in (approvals), it is time to merge the pull request. After the pull request is merged, remember to delete the branch as well (this option will show up as a big button right after you have merged the pull request). If you have not done so, close all the associated tickets fixed by the pull request.","title":"9. Merge and cleanup"},{"location":"odk-workflows/EditorsWorkflow/#10-changelog-optional","text":"It is sometimes difficult to keep track of changes made to an ontology. Some ontology teams opt to document changes in a changelog (simply a text file in your repository) so that when release day comes, you know everything you have changed. This is advisable at least for major changes (such as a new release system, a new pattern or template etc.).","title":"10. Changelog (Optional)"},{"location":"odk-workflows/ManageDocumentation/","text":"Updating the Documentation The documentation for PMDCO is managed in two places (relative to the repository root): The docs directory contains all the files that pertain to the content of the documentation (more below) the mkdocs.yaml file contains the documentation config, in particular its navigation bar and theme. The documentation is hosted using GitHub pages, on a special branch of the repository (called gh-pages ). It is important that this branch is never deleted - it contains all the files GitHub pages needs to render and deploy the site. It is also important to note that the gh-pages branch should never be edited manually . All changes to the docs happen inside the docs directory on the main branch. Editing the docs Changing content All the documentation is contained in the docs directory, and is managed in Markdown . Markdown is a very simple and convenient way to produce text documents with formatting instructions, and is very easy to learn - it is also used, for example, in GitHub issues. This is a normal editing workflow: Open the .md file you want to change in an editor of choice (a simple text editor is often best). IMPORTANT : Do not edit any files in the docs/odk-workflows/ directory. These files are managed by the ODK system and will be overwritten when the repository is upgraded! If you wish to change these files, make an issue on the ODK issue tracker . Perform the edit and save the file Commit the file to a branch, and create a pull request as usual. If your development team likes your changes, merge the docs into main branch. Deploy the documentation (see below) Deploy the documentation The documentation is not automatically updated from the Markdown, and needs to be deployed deliberately. To do this, perform the following steps: In your terminal, navigate to the edit directory of your ontology, e.g.: cd pmdco/src/ontology Now you are ready to build the docs as follows: sh run.sh make update_docs Mkdocs now sets off to build the site from the markdown pages. You will be asked to Enter your username Enter your password (see here for using GitHub access tokens instead) IMPORTANT : Using password based authentication will be deprecated this year (2021). Make sure you read up on personal access tokens if that happens! If everything was successful, you will see a message similar to this one: INFO - Your documentation should shortly be available at: https://materialdigital.github.io/core-ontology/ 3. Just to double check, you can now navigate to your documentation pages (usually https://materialdigital.github.io/core-ontology/). Just make sure you give GitHub 2-5 minutes to build the pages!","title":"Updating the Documentation"},{"location":"odk-workflows/ManageDocumentation/#updating-the-documentation","text":"The documentation for PMDCO is managed in two places (relative to the repository root): The docs directory contains all the files that pertain to the content of the documentation (more below) the mkdocs.yaml file contains the documentation config, in particular its navigation bar and theme. The documentation is hosted using GitHub pages, on a special branch of the repository (called gh-pages ). It is important that this branch is never deleted - it contains all the files GitHub pages needs to render and deploy the site. It is also important to note that the gh-pages branch should never be edited manually . All changes to the docs happen inside the docs directory on the main branch.","title":"Updating the Documentation"},{"location":"odk-workflows/ManageDocumentation/#editing-the-docs","text":"","title":"Editing the docs"},{"location":"odk-workflows/ManageDocumentation/#changing-content","text":"All the documentation is contained in the docs directory, and is managed in Markdown . Markdown is a very simple and convenient way to produce text documents with formatting instructions, and is very easy to learn - it is also used, for example, in GitHub issues. This is a normal editing workflow: Open the .md file you want to change in an editor of choice (a simple text editor is often best). IMPORTANT : Do not edit any files in the docs/odk-workflows/ directory. These files are managed by the ODK system and will be overwritten when the repository is upgraded! If you wish to change these files, make an issue on the ODK issue tracker . Perform the edit and save the file Commit the file to a branch, and create a pull request as usual. If your development team likes your changes, merge the docs into main branch. Deploy the documentation (see below)","title":"Changing content"},{"location":"odk-workflows/ManageDocumentation/#deploy-the-documentation","text":"The documentation is not automatically updated from the Markdown, and needs to be deployed deliberately. To do this, perform the following steps: In your terminal, navigate to the edit directory of your ontology, e.g.: cd pmdco/src/ontology Now you are ready to build the docs as follows: sh run.sh make update_docs Mkdocs now sets off to build the site from the markdown pages. You will be asked to Enter your username Enter your password (see here for using GitHub access tokens instead) IMPORTANT : Using password based authentication will be deprecated this year (2021). Make sure you read up on personal access tokens if that happens! If everything was successful, you will see a message similar to this one: INFO - Your documentation should shortly be available at: https://materialdigital.github.io/core-ontology/ 3. Just to double check, you can now navigate to your documentation pages (usually https://materialdigital.github.io/core-ontology/). Just make sure you give GitHub 2-5 minutes to build the pages!","title":"Deploy the documentation"},{"location":"odk-workflows/ReleaseWorkflow/","text":"The release workflow The release workflow recommended by the ODK is based on GitHub releases and works as follows: Run a release with the ODK Review the release Merge to main branch Create a GitHub release These steps are outlined in detail in the following. Run a release with the ODK Preparation: Ensure that all your pull requests are merged into your main (master) branch Make sure that all changes to main are committed to GitHub ( git status should say that there are no modified files) Locally make sure you have the latest changes from main ( git pull ) Checkout a new branch (e.g. git checkout -b release-2021-01-01 ) You may or may not want to refresh your imports as part of your release strategy (see here ) Make sure you have the latest ODK installed by running docker pull obolibrary/odkfull To actually run the release, you: Open a command line terminal window and navigate to the src/ontology directory ( cd pmdco/src/ontology ) Run release pipeline: sh run.sh make prepare_release -B . Note that for some ontologies, this process can take up to 90 minutes - especially if there are large ontologies you depend on, like PRO or CHEBI. If everything went well, you should see the following output on your machine: Release files are now in ../.. - now you should commit, push and make a release on your git hosting site such as GitHub or GitLab . This will create all the specified release targets (OBO, OWL, JSON, and the variants, ont-full and ont-base) and copy them into your release directory (the top level of your repo). Review the release (Optional) Rough check. This step is frequently skipped, but for the more paranoid among us (like the author of this doc), this is a 3 minute additional effort for some peace of mind. Open the main release (pmdco.owl) in you favourite development environment (i.e. Prot\u00e9g\u00e9) and eyeball the hierarchy. We recommend two simple checks: Does the very top level of the hierarchy look ok? This means that all new terms have been imported/updated correctly. Does at least one change that you know should be in this release appear? For example, a new class. This means that the release was actually based on the recent edit file. Commit your changes to the branch and make a pull request In your GitHub pull request, review the following three files in detail (based on our experience): pmdco.obo - this reflects a useful subset of the whole ontology (everything that can be covered by OBO format). OBO format has that speaking for it: it is very easy to review! pmdco-base.owl - this reflects the asserted axioms in your ontology that you have actually edited. Ideally also take a look at pmdco-full.owl , which may reveal interesting new inferences you did not know about. Note that the diff of this file is sometimes quite large. Like with every pull request, we recommend to always employ a second set of eyes when reviewing a PR! Merge the main branch Once your CI checks have passed, and your reviews are completed, you can now merge the branch into your main branch (don't forget to delete the branch afterwards - a big button will appear after the merge is finished). Create a GitHub release Go to your releases page on GitHub by navigating to your repository, and then clicking on releases (usually on the right, for example: https://github.com/materialdigital/core-ontology/releases). Then click \"Draft new release\" As the tag version you need to choose the date on which your ontologies were build. You can find this, for example, by looking at the pmdco.obo file and check the data-version: property. The date needs to be prefixed with a v , so, for example v2020-02-06 . You can write whatever you want in the release title, but we typically write the date again. The description underneath should contain a concise list of changes or term additions. Click \"Publish release\". Done. Debugging typical ontology release problems Problems with memory When you are dealing with large ontologies, you need a lot of memory. When you see error messages relating to large ontologies such as CHEBI, PRO, NCBITAXON, or Uberon, you should think of memory first, see here . Problems when using OBO format based tools Sometimes you will get cryptic error messages when using legacy tools using OBO format, such as the ontology release tool (OORT), which is also available as part of the ODK docker container. In these cases, you need to track down what axiom or annotation actually caused the breakdown. In our experience (in about 60% of the cases) the problem lies with duplicate annotations ( def , comment ) which are illegal in OBO. Here is an example recipe of how to deal with such a problem: If you get a message like make: *** [cl.Makefile:84: oort] Error 255 you might have a OORT error. To debug this, in your terminal enter sh run.sh make IMP=false PAT=false oort -B (assuming you are already in the ontology folder in your directory) This should show you where the error is in the log (eg multiple different definitions) WARNING: THE FIX BELOW IS NOT IDEAL, YOU SHOULD ALWAYS TRY TO FIX UPSTREAM IF POSSIBLE Open pmdco-edit.owl in Prot\u00e9g\u00e9 and find the offending term and delete all offending issue (e.g. delete ALL definition, if the problem was \"multiple def tags not allowed\") and save. *While this is not idea, as it will remove all definitions from that term, it will be added back again when the term is fixed in the ontology it was imported from and added back in. Rerun sh run.sh make IMP=false PAT=false oort -B and if it all passes, commit your changes to a branch and make a pull request as usual.","title":"The release workflow"},{"location":"odk-workflows/ReleaseWorkflow/#the-release-workflow","text":"The release workflow recommended by the ODK is based on GitHub releases and works as follows: Run a release with the ODK Review the release Merge to main branch Create a GitHub release These steps are outlined in detail in the following.","title":"The release workflow"},{"location":"odk-workflows/ReleaseWorkflow/#run-a-release-with-the-odk","text":"Preparation: Ensure that all your pull requests are merged into your main (master) branch Make sure that all changes to main are committed to GitHub ( git status should say that there are no modified files) Locally make sure you have the latest changes from main ( git pull ) Checkout a new branch (e.g. git checkout -b release-2021-01-01 ) You may or may not want to refresh your imports as part of your release strategy (see here ) Make sure you have the latest ODK installed by running docker pull obolibrary/odkfull To actually run the release, you: Open a command line terminal window and navigate to the src/ontology directory ( cd pmdco/src/ontology ) Run release pipeline: sh run.sh make prepare_release -B . Note that for some ontologies, this process can take up to 90 minutes - especially if there are large ontologies you depend on, like PRO or CHEBI. If everything went well, you should see the following output on your machine: Release files are now in ../.. - now you should commit, push and make a release on your git hosting site such as GitHub or GitLab . This will create all the specified release targets (OBO, OWL, JSON, and the variants, ont-full and ont-base) and copy them into your release directory (the top level of your repo).","title":"Run a release with the ODK"},{"location":"odk-workflows/ReleaseWorkflow/#review-the-release","text":"(Optional) Rough check. This step is frequently skipped, but for the more paranoid among us (like the author of this doc), this is a 3 minute additional effort for some peace of mind. Open the main release (pmdco.owl) in you favourite development environment (i.e. Prot\u00e9g\u00e9) and eyeball the hierarchy. We recommend two simple checks: Does the very top level of the hierarchy look ok? This means that all new terms have been imported/updated correctly. Does at least one change that you know should be in this release appear? For example, a new class. This means that the release was actually based on the recent edit file. Commit your changes to the branch and make a pull request In your GitHub pull request, review the following three files in detail (based on our experience): pmdco.obo - this reflects a useful subset of the whole ontology (everything that can be covered by OBO format). OBO format has that speaking for it: it is very easy to review! pmdco-base.owl - this reflects the asserted axioms in your ontology that you have actually edited. Ideally also take a look at pmdco-full.owl , which may reveal interesting new inferences you did not know about. Note that the diff of this file is sometimes quite large. Like with every pull request, we recommend to always employ a second set of eyes when reviewing a PR!","title":"Review the release"},{"location":"odk-workflows/ReleaseWorkflow/#merge-the-main-branch","text":"Once your CI checks have passed, and your reviews are completed, you can now merge the branch into your main branch (don't forget to delete the branch afterwards - a big button will appear after the merge is finished).","title":"Merge the main branch"},{"location":"odk-workflows/ReleaseWorkflow/#create-a-github-release","text":"Go to your releases page on GitHub by navigating to your repository, and then clicking on releases (usually on the right, for example: https://github.com/materialdigital/core-ontology/releases). Then click \"Draft new release\" As the tag version you need to choose the date on which your ontologies were build. You can find this, for example, by looking at the pmdco.obo file and check the data-version: property. The date needs to be prefixed with a v , so, for example v2020-02-06 . You can write whatever you want in the release title, but we typically write the date again. The description underneath should contain a concise list of changes or term additions. Click \"Publish release\". Done.","title":"Create a GitHub release"},{"location":"odk-workflows/ReleaseWorkflow/#debugging-typical-ontology-release-problems","text":"","title":"Debugging typical ontology release problems"},{"location":"odk-workflows/ReleaseWorkflow/#problems-with-memory","text":"When you are dealing with large ontologies, you need a lot of memory. When you see error messages relating to large ontologies such as CHEBI, PRO, NCBITAXON, or Uberon, you should think of memory first, see here .","title":"Problems with memory"},{"location":"odk-workflows/ReleaseWorkflow/#problems-when-using-obo-format-based-tools","text":"Sometimes you will get cryptic error messages when using legacy tools using OBO format, such as the ontology release tool (OORT), which is also available as part of the ODK docker container. In these cases, you need to track down what axiom or annotation actually caused the breakdown. In our experience (in about 60% of the cases) the problem lies with duplicate annotations ( def , comment ) which are illegal in OBO. Here is an example recipe of how to deal with such a problem: If you get a message like make: *** [cl.Makefile:84: oort] Error 255 you might have a OORT error. To debug this, in your terminal enter sh run.sh make IMP=false PAT=false oort -B (assuming you are already in the ontology folder in your directory) This should show you where the error is in the log (eg multiple different definitions) WARNING: THE FIX BELOW IS NOT IDEAL, YOU SHOULD ALWAYS TRY TO FIX UPSTREAM IF POSSIBLE Open pmdco-edit.owl in Prot\u00e9g\u00e9 and find the offending term and delete all offending issue (e.g. delete ALL definition, if the problem was \"multiple def tags not allowed\") and save. *While this is not idea, as it will remove all definitions from that term, it will be added back again when the term is fixed in the ontology it was imported from and added back in. Rerun sh run.sh make IMP=false PAT=false oort -B and if it all passes, commit your changes to a branch and make a pull request as usual.","title":"Problems when using OBO format based tools"},{"location":"odk-workflows/RepoManagement/","text":"Managing your ODK repository Updating your ODK repository Your ODK repositories configuration is managed in src/ontology/pmdco-odk.yaml . The ODK Project Configuration Schema defines all possible parameters that can be used in this config YAML. Once you have made your changes, you can run the following to apply your changes to the repository: sh run.sh make update_repo There are a large number of options that can be set to configure your ODK, but we will only discuss a few of them here. NOTE for Windows users: You may get a cryptic failure such as Set Illegal Option - if the update script located in src/scripts/update_repo.sh was saved using Windows Line endings. These need to change to unix line endings. In Notepad++, for example, you can click on Edit->EOL Conversion->Unix LF to change this. Managing imports You can use the update repository workflow described on this page to perform the following operations to your imports: Add a new import Modify an existing import Remove an import you no longer want Customise an import We will discuss all these workflows in the following. Add new import To add a new import, you first edit your odk config as described above , adding an id to the product list in the import_group section (for the sake of this example, we assume you already import RO, and your goal is to also import GO): import_group: products: - id: ro - id: go Note: our ODK file should only have one import_group which can contain multiple imports (in the products section). Next, you run the update repo workflow to apply these changes. Note that by default, this module is going to be a SLME Bottom module, see here . To change that or customise your module, see section \"Customise an import\". To finalise the addition of your import, perform the following steps: Add an import statement to your src/ontology/pmdco-edit.owl file. We suggest to do this using a text editor, by simply copying an existing import declaration and renaming it to the new ontology import, for example as follows: ... Ontology(<https://w3id.org/pmd/co/pmdco.owl> Import(<https://w3id.org/pmd/co/pmdco/imports/ro_import.owl>) Import(<https://w3id.org/pmd/co/pmdco/imports/go_import.owl>) ... Add your imports redirect to your catalog file src/ontology/catalog-v001.xml , for example: <uri name=\"http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl\" uri=\"imports/go_import.owl\"/> Test whether everything is in order: Refresh your import Open in your Ontology Editor of choice (Protege) and ensure that the expected terms are imported. Note: The catalog file src/ontology/catalog-v001.xml has one purpose: redirecting imports from URLs to local files. For example, if you have Import(<http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl>) in your editors file (the ontology) and <uri name=\"https://w3id.org/pmd/co/pmdco/imports/go_import.owl\" uri=\"imports/go_import.owl\"/> in your catalog, tools like robot or Prot\u00e9g\u00e9 will recognize the statement in the catalog file to redirect the URL http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl to the local file imports/go_import.owl (which is in your src/ontology directory). Modify an existing import If you simply wish to refresh your import in light of new terms, see here . If you wish to change the type of your module see section \"Customise an import\". Remove an existing import To remove an existing import, perform the following steps: remove the import declaration from your src/ontology/pmdco-edit.owl . remove the id from your src/ontology/pmdco-odk.yaml , eg. - id: go from the list of products in the import_group . run update repo workflow delete the associated files manually: src/imports/go_import.owl src/imports/go_terms.txt Remove the respective entry from the src/ontology/catalog-v001.xml file. Customise an import By default, an import module extracted from a source ontology will be a SLME module, see here . There are various options to change the default. The following change to your repo config ( src/ontology/pmdco-odk.yaml ) will switch the go import from an SLME module to a simple ROBOT filter module: import_group: products: - id: ro - id: go module_type: filter A ROBOT filter module is, essentially, importing all external terms declared by your ontology (see here on how to declare external terms to be imported). Note that the filter module does not consider terms/annotations from namespaces other than the base-namespace of the ontology itself. For example, in the example of GO above, only annotations / axioms related to the GO base IRI (http://purl.obolibrary.org/obo/GO_) would be considered. This behaviour can be changed by adding additional base IRIs as follows: import_group: products: - id: go module_type: filter base_iris: - http://purl.obolibrary.org/obo/GO_ - http://purl.obolibrary.org/obo/CL_ - http://purl.obolibrary.org/obo/BFO If you wish to customise your import entirely, you can specify your own ROBOT command to do so. To do that, add the following to your repo config ( src/ontology/pmdco-odk.yaml ): import_group: products: - id: ro - id: go module_type: custom Now add a new goal in your custom Makefile ( src/ontology/pmdco.Makefile , not src/ontology/Makefile ). imports/go_import.owl: mirror/ro.owl imports/ro_terms_combined.txt if [ $(IMP) = true ]; then $(ROBOT) query -i $< --update ../sparql/preprocess-module.ru \\ extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\ query --update ../sparql/inject-subset-declaration.ru --update ../sparql/postprocess-module.ru \\ annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl && mv $@.tmp.owl $@; fi Now feel free to change this goal to do whatever you wish it to do! It probably makes some sense (albeit not being a strict necessity), to leave most of the goal instead and replace only: extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\ to another ROBOT pipeline. Add a component A component is an import which belongs to your ontology, e.g. is managed by you and your team. Open src/ontology/pmdco-odk.yaml If you dont have it yet, add a new top level section components Under the components section, add a new section called products . This is where all your components are specified Under the products section, add a new component, e.g. - filename: mycomp.owl Example components: products: - filename: mycomp.owl When running sh run.sh make update_repo , a new file src/ontology/components/mycomp.owl will be created which you can edit as you see fit. Typical ways to edit: Using a ROBOT template to generate the component (see below) Manually curating the component separately with Prot\u00e9g\u00e9 or any other editor Providing a components/mycomp.owl: make target in src/ontology/pmdco.Makefile and provide a custom command to generate the component WARNING : Note that the custom rule to generate the component MUST NOT depend on any other ODK-generated file such as seed files and the like (see issue ). Providing an additional attribute for the component in src/ontology/pmdco-odk.yaml , source , to specify that this component should simply be downloaded from somewhere on the web. Adding a new component based on a ROBOT template Since ODK 1.3.2, it is possible to simply link a ROBOT template to a component without having to specify any of the import logic. In order to add a new component that is connected to one or more template files, follow these steps: Open src/ontology/pmdco-odk.yaml . Make sure that use_templates: TRUE is set in the global project options. You should also make sure that use_context: TRUE is set in case you are using prefixes in your templates that are not known to robot , such as OMOP: , CPONT: and more. All non-standard prefixes you are using should be added to config/context.json . Add another component to the products section. To activate this component to be template-driven, simply say: use_template: TRUE . This will create an empty template for you in the templates directory, which will automatically be processed when recreating the component (e.g. run.bat make recreate-mycomp ). If you want to use more than one component, use the templates field to add as many template names as you wish. ODK will look for them in the src/templates directory. Advanced: If you want to provide additional processing options, you can use the template_options field. This should be a string with option from robot template . One typical example for additional options you may want to provide is --add-prefixes config/context.json to ensure the prefix map of your context is provided to robot , see above. Example : components: products: - filename: mycomp.owl use_template: TRUE template_options: --add-prefixes config/context.json templates: - template1.tsv - template2.tsv Note : if your mirror is particularly large and complex, read this ODK recommendation .","title":"Managing your ODK repository"},{"location":"odk-workflows/RepoManagement/#managing-your-odk-repository","text":"","title":"Managing your ODK repository"},{"location":"odk-workflows/RepoManagement/#updating-your-odk-repository","text":"Your ODK repositories configuration is managed in src/ontology/pmdco-odk.yaml . The ODK Project Configuration Schema defines all possible parameters that can be used in this config YAML. Once you have made your changes, you can run the following to apply your changes to the repository: sh run.sh make update_repo There are a large number of options that can be set to configure your ODK, but we will only discuss a few of them here. NOTE for Windows users: You may get a cryptic failure such as Set Illegal Option - if the update script located in src/scripts/update_repo.sh was saved using Windows Line endings. These need to change to unix line endings. In Notepad++, for example, you can click on Edit->EOL Conversion->Unix LF to change this.","title":"Updating your ODK repository"},{"location":"odk-workflows/RepoManagement/#managing-imports","text":"You can use the update repository workflow described on this page to perform the following operations to your imports: Add a new import Modify an existing import Remove an import you no longer want Customise an import We will discuss all these workflows in the following.","title":"Managing imports"},{"location":"odk-workflows/RepoManagement/#add-new-import","text":"To add a new import, you first edit your odk config as described above , adding an id to the product list in the import_group section (for the sake of this example, we assume you already import RO, and your goal is to also import GO): import_group: products: - id: ro - id: go Note: our ODK file should only have one import_group which can contain multiple imports (in the products section). Next, you run the update repo workflow to apply these changes. Note that by default, this module is going to be a SLME Bottom module, see here . To change that or customise your module, see section \"Customise an import\". To finalise the addition of your import, perform the following steps: Add an import statement to your src/ontology/pmdco-edit.owl file. We suggest to do this using a text editor, by simply copying an existing import declaration and renaming it to the new ontology import, for example as follows: ... Ontology(<https://w3id.org/pmd/co/pmdco.owl> Import(<https://w3id.org/pmd/co/pmdco/imports/ro_import.owl>) Import(<https://w3id.org/pmd/co/pmdco/imports/go_import.owl>) ... Add your imports redirect to your catalog file src/ontology/catalog-v001.xml , for example: <uri name=\"http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl\" uri=\"imports/go_import.owl\"/> Test whether everything is in order: Refresh your import Open in your Ontology Editor of choice (Protege) and ensure that the expected terms are imported. Note: The catalog file src/ontology/catalog-v001.xml has one purpose: redirecting imports from URLs to local files. For example, if you have Import(<http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl>) in your editors file (the ontology) and <uri name=\"https://w3id.org/pmd/co/pmdco/imports/go_import.owl\" uri=\"imports/go_import.owl\"/> in your catalog, tools like robot or Prot\u00e9g\u00e9 will recognize the statement in the catalog file to redirect the URL http://purl.obolibrary.org/obo/pmdco/imports/go_import.owl to the local file imports/go_import.owl (which is in your src/ontology directory).","title":"Add new import"},{"location":"odk-workflows/RepoManagement/#modify-an-existing-import","text":"If you simply wish to refresh your import in light of new terms, see here . If you wish to change the type of your module see section \"Customise an import\".","title":"Modify an existing import"},{"location":"odk-workflows/RepoManagement/#remove-an-existing-import","text":"To remove an existing import, perform the following steps: remove the import declaration from your src/ontology/pmdco-edit.owl . remove the id from your src/ontology/pmdco-odk.yaml , eg. - id: go from the list of products in the import_group . run update repo workflow delete the associated files manually: src/imports/go_import.owl src/imports/go_terms.txt Remove the respective entry from the src/ontology/catalog-v001.xml file.","title":"Remove an existing import"},{"location":"odk-workflows/RepoManagement/#customise-an-import","text":"By default, an import module extracted from a source ontology will be a SLME module, see here . There are various options to change the default. The following change to your repo config ( src/ontology/pmdco-odk.yaml ) will switch the go import from an SLME module to a simple ROBOT filter module: import_group: products: - id: ro - id: go module_type: filter A ROBOT filter module is, essentially, importing all external terms declared by your ontology (see here on how to declare external terms to be imported). Note that the filter module does not consider terms/annotations from namespaces other than the base-namespace of the ontology itself. For example, in the example of GO above, only annotations / axioms related to the GO base IRI (http://purl.obolibrary.org/obo/GO_) would be considered. This behaviour can be changed by adding additional base IRIs as follows: import_group: products: - id: go module_type: filter base_iris: - http://purl.obolibrary.org/obo/GO_ - http://purl.obolibrary.org/obo/CL_ - http://purl.obolibrary.org/obo/BFO If you wish to customise your import entirely, you can specify your own ROBOT command to do so. To do that, add the following to your repo config ( src/ontology/pmdco-odk.yaml ): import_group: products: - id: ro - id: go module_type: custom Now add a new goal in your custom Makefile ( src/ontology/pmdco.Makefile , not src/ontology/Makefile ). imports/go_import.owl: mirror/ro.owl imports/ro_terms_combined.txt if [ $(IMP) = true ]; then $(ROBOT) query -i $< --update ../sparql/preprocess-module.ru \\ extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\ query --update ../sparql/inject-subset-declaration.ru --update ../sparql/postprocess-module.ru \\ annotate --ontology-iri $(ONTBASE)/$@ $(ANNOTATE_ONTOLOGY_VERSION) --output $@.tmp.owl && mv $@.tmp.owl $@; fi Now feel free to change this goal to do whatever you wish it to do! It probably makes some sense (albeit not being a strict necessity), to leave most of the goal instead and replace only: extract -T imports/ro_terms_combined.txt --force true --individuals exclude --method BOT \\ to another ROBOT pipeline.","title":"Customise an import"},{"location":"odk-workflows/RepoManagement/#add-a-component","text":"A component is an import which belongs to your ontology, e.g. is managed by you and your team. Open src/ontology/pmdco-odk.yaml If you dont have it yet, add a new top level section components Under the components section, add a new section called products . This is where all your components are specified Under the products section, add a new component, e.g. - filename: mycomp.owl Example components: products: - filename: mycomp.owl When running sh run.sh make update_repo , a new file src/ontology/components/mycomp.owl will be created which you can edit as you see fit. Typical ways to edit: Using a ROBOT template to generate the component (see below) Manually curating the component separately with Prot\u00e9g\u00e9 or any other editor Providing a components/mycomp.owl: make target in src/ontology/pmdco.Makefile and provide a custom command to generate the component WARNING : Note that the custom rule to generate the component MUST NOT depend on any other ODK-generated file such as seed files and the like (see issue ). Providing an additional attribute for the component in src/ontology/pmdco-odk.yaml , source , to specify that this component should simply be downloaded from somewhere on the web.","title":"Add a component"},{"location":"odk-workflows/RepoManagement/#adding-a-new-component-based-on-a-robot-template","text":"Since ODK 1.3.2, it is possible to simply link a ROBOT template to a component without having to specify any of the import logic. In order to add a new component that is connected to one or more template files, follow these steps: Open src/ontology/pmdco-odk.yaml . Make sure that use_templates: TRUE is set in the global project options. You should also make sure that use_context: TRUE is set in case you are using prefixes in your templates that are not known to robot , such as OMOP: , CPONT: and more. All non-standard prefixes you are using should be added to config/context.json . Add another component to the products section. To activate this component to be template-driven, simply say: use_template: TRUE . This will create an empty template for you in the templates directory, which will automatically be processed when recreating the component (e.g. run.bat make recreate-mycomp ). If you want to use more than one component, use the templates field to add as many template names as you wish. ODK will look for them in the src/templates directory. Advanced: If you want to provide additional processing options, you can use the template_options field. This should be a string with option from robot template . One typical example for additional options you may want to provide is --add-prefixes config/context.json to ensure the prefix map of your context is provided to robot , see above. Example : components: products: - filename: mycomp.owl use_template: TRUE template_options: --add-prefixes config/context.json templates: - template1.tsv - template2.tsv Note : if your mirror is particularly large and complex, read this ODK recommendation .","title":"Adding a new component based on a ROBOT template"},{"location":"odk-workflows/RepositoryFileStructure/","text":"Repository structure The main kinds of files in the repository: Release files Imports Components Release files Release file are the file that are considered part of the official ontology release and to be used by the community. A detailed description of the release artefacts can be found here . Imports Imports are subsets of external ontologies that contain terms and axioms you would like to re-use in your ontology. These are considered \"external\", like dependencies in software development, and are not included in your \"base\" product, which is the release artefact which contains only those axioms that you personally maintain. These are the current imports in PMDCO Import URL Type bfo https://raw.githubusercontent.com/BFO-ontology/BFO-2020/release-2024-01-29/src/owl/bfo-core.ttl mirror iao http://purl.obolibrary.org/obo/iao.owl custom obi http://purl.obolibrary.org/obo/obi.owl custom chebi https://ftp.ebi.ac.uk/pub/databases/chebi/ontology/chebi_lite.obo custom Components Components, in contrast to imports, are considered full members of the ontology. This means that any axiom in a component is also included in the ontology base - which means it is considered native to the ontology. While this sounds complicated, consider this: conceptually, no component should be part of more than one ontology. If that seems to be the case, we are most likely talking about an import. Components are often not needed for ontologies, but there are some use cases: There is an automated process that generates and re-generates a part of the ontology A part of the ontology is managed in ROBOT templates The expressivity of the component is higher than the format of the edit file. For example, people still choose to manage their ontology in OBO format (they should not) missing out on a lot of owl features. They may choose to manage logic that is beyond OBO in a specific OWL component. These are the components in PMDCO Filename URL imports-edit.owl None pmdco-shared.owl None pmdco-axioms-shared.owl None pmdco-qualities.owl None pmdco-materials.owl None pmdco-manufacturing.owl None pmdco-logistics.owl None pmdco-devices.owl None pmdco-datatransformation.owl None pmdco-characterization.owl None","title":"Repository structure"},{"location":"odk-workflows/RepositoryFileStructure/#repository-structure","text":"The main kinds of files in the repository: Release files Imports Components","title":"Repository structure"},{"location":"odk-workflows/RepositoryFileStructure/#release-files","text":"Release file are the file that are considered part of the official ontology release and to be used by the community. A detailed description of the release artefacts can be found here .","title":"Release files"},{"location":"odk-workflows/RepositoryFileStructure/#imports","text":"Imports are subsets of external ontologies that contain terms and axioms you would like to re-use in your ontology. These are considered \"external\", like dependencies in software development, and are not included in your \"base\" product, which is the release artefact which contains only those axioms that you personally maintain. These are the current imports in PMDCO Import URL Type bfo https://raw.githubusercontent.com/BFO-ontology/BFO-2020/release-2024-01-29/src/owl/bfo-core.ttl mirror iao http://purl.obolibrary.org/obo/iao.owl custom obi http://purl.obolibrary.org/obo/obi.owl custom chebi https://ftp.ebi.ac.uk/pub/databases/chebi/ontology/chebi_lite.obo custom","title":"Imports"},{"location":"odk-workflows/RepositoryFileStructure/#components","text":"Components, in contrast to imports, are considered full members of the ontology. This means that any axiom in a component is also included in the ontology base - which means it is considered native to the ontology. While this sounds complicated, consider this: conceptually, no component should be part of more than one ontology. If that seems to be the case, we are most likely talking about an import. Components are often not needed for ontologies, but there are some use cases: There is an automated process that generates and re-generates a part of the ontology A part of the ontology is managed in ROBOT templates The expressivity of the component is higher than the format of the edit file. For example, people still choose to manage their ontology in OBO format (they should not) missing out on a lot of owl features. They may choose to manage logic that is beyond OBO in a specific OWL component. These are the components in PMDCO Filename URL imports-edit.owl None pmdco-shared.owl None pmdco-axioms-shared.owl None pmdco-qualities.owl None pmdco-materials.owl None pmdco-manufacturing.owl None pmdco-logistics.owl None pmdco-devices.owl None pmdco-datatransformation.owl None pmdco-characterization.owl None","title":"Components"},{"location":"odk-workflows/SettingUpDockerForODK/","text":"Setting up your Docker environment for ODK use One of the most frequent problems with running the ODK for the first time is failure because of lack of memory. This can look like a Java OutOfMemory exception, but more often than not it will appear as something like an Error 137 . There are two places you need to consider to set your memory: Your src/ontology/run.sh (or run.bat) file. You can set the memory in there by adding robot_java_args: '-Xmx8G' to your src/ontology/pmdco-odk.yaml file, see for example here . Set your docker memory. By default, it should be about 10-20% more than your robot_java_args variable. You can manage your memory settings by right-clicking on the docker whale in your system bar-->Preferences-->Resources-->Advanced, see picture below.","title":"Setting up your Docker environment for ODK use"},{"location":"odk-workflows/SettingUpDockerForODK/#setting-up-your-docker-environment-for-odk-use","text":"One of the most frequent problems with running the ODK for the first time is failure because of lack of memory. This can look like a Java OutOfMemory exception, but more often than not it will appear as something like an Error 137 . There are two places you need to consider to set your memory: Your src/ontology/run.sh (or run.bat) file. You can set the memory in there by adding robot_java_args: '-Xmx8G' to your src/ontology/pmdco-odk.yaml file, see for example here . Set your docker memory. By default, it should be about 10-20% more than your robot_java_args variable. You can manage your memory settings by right-clicking on the docker whale in your system bar-->Preferences-->Resources-->Advanced, see picture below.","title":"Setting up your Docker environment for ODK use"},{"location":"odk-workflows/UpdateImports/","text":"Update Imports Workflow This page discusses how to update the contents of your imports, like adding or removing terms. If you are looking to customise imports, like changing the module type, see here . Importing a new term Note: some ontologies now use a merged-import system to manage dynamic imports, for these please follow instructions in the section title \"Using the Base Module approach\". Importing a new term is split into two sub-phases: Declaring the terms to be imported Refreshing imports dynamically Declaring terms to be imported There are three ways to declare terms that are to be imported from an external ontology. Choose the appropriate one for your particular scenario (all three can be used in parallel if need be): Prot\u00e9g\u00e9-based declaration Using term files Using the custom import template Prot\u00e9g\u00e9-based declaration This workflow is to be avoided, but may be appropriate if the editor does not have access to the ODK docker container . This approach also applies to ontologies that use base module import approach. Open your ontology (edit file) in Prot\u00e9g\u00e9 (5.5+). Select 'owl:Thing' Add a new class as usual. Paste the full iri in the 'Name:' field, for example, http://purl.obolibrary.org/obo/CHEBI_50906. Click 'OK' Now you can use this term for example to construct logical definitions. The next time the imports are refreshed (see how to refresh here ), the metadata (labels, definitions, etc.) for this term are imported from the respective external source ontology and becomes visible in your ontology. Using term files Every import has, by default a term file associated with it, which can be found in the imports directory. For example, if you have a GO import in src/ontology/go_import.owl , you will also have an associated term file src/ontology/go_terms.txt . You can add terms in there simply as a list: GO:0008150 GO:0008151 Now you can run the refresh imports workflow ) and the two terms will be imported. Using the custom import template This workflow is appropriate if: You prefer to manage all your imported terms in a single file (rather than multiple files like in the \"Using term files\" workflow above). You wish to augment your imported ontologies with additional information. This requires a cautionary discussion. To enable this workflow, you add the following to your ODK config file ( src/ontology/pmdco-odk.yaml ), and update the repository : use_custom_import_module: TRUE Now you can manage your imported terms directly in the custom external terms template, which is located at src/templates/external_import.owl . Note that this file is a ROBOT template , and can, in principle, be extended to include any axioms you like. Before extending the template, however, read the following carefully. The main purpose of the custom import template is to enable the management off all terms to be imported in a centralised place. To enable that, you do not have to do anything other than maintaining the template. So if you, say currently import APOLLO_SV:00000480 , and you wish to import APOLLO_SV:00000532 , you simply add a row like this: ID Entity Type ID TYPE APOLLO_SV:00000480 owl:Class APOLLO_SV:00000532 owl:Class When the imports are refreshed see imports refresh workflow , the term(s) will simply be imported from the configured ontologies. Now, if you wish to extend the Makefile (which is beyond these instructions) and add, say, synonyms to the imported terms, you can do that, but you need to (a) preserve the ID and ENTITY columns and (b) ensure that the ROBOT template is valid otherwise, see here . WARNING . Note that doing this is a widespread antipattern (see related issue ). You should not change the axioms of terms that do not belong into your ontology unless necessary - such changes should always be pushed into the ontology where they belong. However, since people are doing it, whether the OBO Foundry likes it or not, at least using the custom imports module as described here localises the changes to a single simple template and ensures that none of the annotations added this way are merged into the base file . Refresh imports If you want to refresh the import yourself (this may be necessary to pass the travis tests), and you have the ODK installed, you can do the following (using go as an example): First, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory). cd src/ontology Then, you regenerate the import that will now include any new terms you have added. Note: You must have docker installed . sh run.sh make PAT=false imports/go_import.owl -B Since ODK 1.2.27, it is also possible to simply run the following, which is the same as the above: sh run.sh make refresh-go Note that in case you changed the defaults, you need to add IMP=true and/or MIR=true to the command below: sh run.sh make IMP=true MIR=true PAT=false imports/go_import.owl -B If you wish to skip refreshing the mirror, i.e. skip downloading the latest version of the source ontology for your import (e.g. go.owl for your go import) you can set MIR=false instead, which will do the exact same thing as the above, but is easier to remember: sh run.sh make IMP=true MIR=false PAT=false imports/go_import.owl -B Using the Base Module approach Since ODK 1.2.31, we support an entirely new approach to generate modules: Using base files. The idea is to only import axioms from ontologies that actually belong to it . A base file is a subset of the ontology that only contains those axioms that nominally belong there. In other words, the base file does not contain any axioms that belong to another ontology. An example would be this: Imagine this being the full Uberon ontology: Axiom 1: BFO:123 SubClassOf BFO:124 Axiom 1: UBERON:123 SubClassOf BFO:123 Axiom 1: UBERON:124 SubClassOf UBERON 123 The base file is the set of all axioms that are about UBERON terms: Axiom 1: UBERON:123 SubClassOf BFO:123 Axiom 1: UBERON:124 SubClassOf UBERON 123 I.e. Axiom 1: BFO:123 SubClassOf BFO:124 Gets removed. The base file pipeline is a bit more complex than the normal pipelines, because of the logical interactions between the imported ontologies. This is solved by _first merging all mirrors into one huge file and then extracting one mega module from it. Example: Let's say we are importing terms from Uberon, GO and RO in our ontologies. When we use the base pipelines, we 1) First obtain the base (usually by simply downloading it, but there is also an option now to create it with ROBOT) 2) We merge all base files into one big pile 3) Then we extract a single module imports/merged_import.owl The first implementation of this pipeline is PATO, see https://github.com/pato-ontology/pato/blob/master/src/ontology/pato-odk.yaml. To check if your ontology uses this method, check src/ontology/pmdco-odk.yaml to see if use_base_merging: TRUE is declared under import_group If your ontology uses Base Module approach, please use the following steps: First, add the term to be imported to the term file associated with it (see above \"Using term files\" section if this is not clear to you) Next, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory). cd src/ontology Then refresh imports by running sh run.sh make imports/merged_import.owl Note: if your mirrors are updated, you can run sh run.sh make no-mirror-refresh-merged This requires quite a bit of memory on your local machine, so if you encounter an error, it might be a lack of memory on your computer. A solution would be to create a ticket in an issue tracker requesting for the term to be imported, and one of the local devs should pick this up and run the import for you. Lastly, restart Prot\u00e9g\u00e9, and the term should be imported in ready to be used.","title":"Update Imports Workflow"},{"location":"odk-workflows/UpdateImports/#update-imports-workflow","text":"This page discusses how to update the contents of your imports, like adding or removing terms. If you are looking to customise imports, like changing the module type, see here .","title":"Update Imports Workflow"},{"location":"odk-workflows/UpdateImports/#importing-a-new-term","text":"Note: some ontologies now use a merged-import system to manage dynamic imports, for these please follow instructions in the section title \"Using the Base Module approach\". Importing a new term is split into two sub-phases: Declaring the terms to be imported Refreshing imports dynamically","title":"Importing a new term"},{"location":"odk-workflows/UpdateImports/#declaring-terms-to-be-imported","text":"There are three ways to declare terms that are to be imported from an external ontology. Choose the appropriate one for your particular scenario (all three can be used in parallel if need be): Prot\u00e9g\u00e9-based declaration Using term files Using the custom import template","title":"Declaring terms to be imported"},{"location":"odk-workflows/UpdateImports/#protege-based-declaration","text":"This workflow is to be avoided, but may be appropriate if the editor does not have access to the ODK docker container . This approach also applies to ontologies that use base module import approach. Open your ontology (edit file) in Prot\u00e9g\u00e9 (5.5+). Select 'owl:Thing' Add a new class as usual. Paste the full iri in the 'Name:' field, for example, http://purl.obolibrary.org/obo/CHEBI_50906. Click 'OK' Now you can use this term for example to construct logical definitions. The next time the imports are refreshed (see how to refresh here ), the metadata (labels, definitions, etc.) for this term are imported from the respective external source ontology and becomes visible in your ontology.","title":"Prot\u00e9g\u00e9-based declaration"},{"location":"odk-workflows/UpdateImports/#using-term-files","text":"Every import has, by default a term file associated with it, which can be found in the imports directory. For example, if you have a GO import in src/ontology/go_import.owl , you will also have an associated term file src/ontology/go_terms.txt . You can add terms in there simply as a list: GO:0008150 GO:0008151 Now you can run the refresh imports workflow ) and the two terms will be imported.","title":"Using term files"},{"location":"odk-workflows/UpdateImports/#using-the-custom-import-template","text":"This workflow is appropriate if: You prefer to manage all your imported terms in a single file (rather than multiple files like in the \"Using term files\" workflow above). You wish to augment your imported ontologies with additional information. This requires a cautionary discussion. To enable this workflow, you add the following to your ODK config file ( src/ontology/pmdco-odk.yaml ), and update the repository : use_custom_import_module: TRUE Now you can manage your imported terms directly in the custom external terms template, which is located at src/templates/external_import.owl . Note that this file is a ROBOT template , and can, in principle, be extended to include any axioms you like. Before extending the template, however, read the following carefully. The main purpose of the custom import template is to enable the management off all terms to be imported in a centralised place. To enable that, you do not have to do anything other than maintaining the template. So if you, say currently import APOLLO_SV:00000480 , and you wish to import APOLLO_SV:00000532 , you simply add a row like this: ID Entity Type ID TYPE APOLLO_SV:00000480 owl:Class APOLLO_SV:00000532 owl:Class When the imports are refreshed see imports refresh workflow , the term(s) will simply be imported from the configured ontologies. Now, if you wish to extend the Makefile (which is beyond these instructions) and add, say, synonyms to the imported terms, you can do that, but you need to (a) preserve the ID and ENTITY columns and (b) ensure that the ROBOT template is valid otherwise, see here . WARNING . Note that doing this is a widespread antipattern (see related issue ). You should not change the axioms of terms that do not belong into your ontology unless necessary - such changes should always be pushed into the ontology where they belong. However, since people are doing it, whether the OBO Foundry likes it or not, at least using the custom imports module as described here localises the changes to a single simple template and ensures that none of the annotations added this way are merged into the base file .","title":"Using the custom import template"},{"location":"odk-workflows/UpdateImports/#refresh-imports","text":"If you want to refresh the import yourself (this may be necessary to pass the travis tests), and you have the ODK installed, you can do the following (using go as an example): First, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory). cd src/ontology Then, you regenerate the import that will now include any new terms you have added. Note: You must have docker installed . sh run.sh make PAT=false imports/go_import.owl -B Since ODK 1.2.27, it is also possible to simply run the following, which is the same as the above: sh run.sh make refresh-go Note that in case you changed the defaults, you need to add IMP=true and/or MIR=true to the command below: sh run.sh make IMP=true MIR=true PAT=false imports/go_import.owl -B If you wish to skip refreshing the mirror, i.e. skip downloading the latest version of the source ontology for your import (e.g. go.owl for your go import) you can set MIR=false instead, which will do the exact same thing as the above, but is easier to remember: sh run.sh make IMP=true MIR=false PAT=false imports/go_import.owl -B","title":"Refresh imports"},{"location":"odk-workflows/UpdateImports/#using-the-base-module-approach","text":"Since ODK 1.2.31, we support an entirely new approach to generate modules: Using base files. The idea is to only import axioms from ontologies that actually belong to it . A base file is a subset of the ontology that only contains those axioms that nominally belong there. In other words, the base file does not contain any axioms that belong to another ontology. An example would be this: Imagine this being the full Uberon ontology: Axiom 1: BFO:123 SubClassOf BFO:124 Axiom 1: UBERON:123 SubClassOf BFO:123 Axiom 1: UBERON:124 SubClassOf UBERON 123 The base file is the set of all axioms that are about UBERON terms: Axiom 1: UBERON:123 SubClassOf BFO:123 Axiom 1: UBERON:124 SubClassOf UBERON 123 I.e. Axiom 1: BFO:123 SubClassOf BFO:124 Gets removed. The base file pipeline is a bit more complex than the normal pipelines, because of the logical interactions between the imported ontologies. This is solved by _first merging all mirrors into one huge file and then extracting one mega module from it. Example: Let's say we are importing terms from Uberon, GO and RO in our ontologies. When we use the base pipelines, we 1) First obtain the base (usually by simply downloading it, but there is also an option now to create it with ROBOT) 2) We merge all base files into one big pile 3) Then we extract a single module imports/merged_import.owl The first implementation of this pipeline is PATO, see https://github.com/pato-ontology/pato/blob/master/src/ontology/pato-odk.yaml. To check if your ontology uses this method, check src/ontology/pmdco-odk.yaml to see if use_base_merging: TRUE is declared under import_group If your ontology uses Base Module approach, please use the following steps: First, add the term to be imported to the term file associated with it (see above \"Using term files\" section if this is not clear to you) Next, you navigate in your terminal to the ontology directory (underneath src in your hpo root directory). cd src/ontology Then refresh imports by running sh run.sh make imports/merged_import.owl Note: if your mirrors are updated, you can run sh run.sh make no-mirror-refresh-merged This requires quite a bit of memory on your local machine, so if you encounter an error, it might be a lack of memory on your computer. A solution would be to create a ticket in an issue tracker requesting for the term to be imported, and one of the local devs should pick this up and run the import for you. Lastly, restart Prot\u00e9g\u00e9, and the term should be imported in ready to be used.","title":"Using the Base Module approach"},{"location":"odk-workflows/components/","text":"Adding components to an ODK repo For details on what components are, please see component section of repository file structure document . To add custom components to an ODK repo, please follow the following steps: 1) Locate your odk yaml file and open it with your favourite text editor (src/ontology/pmdco-odk.yaml) 2) Search if there is already a component section to the yaml file, if not add it accordingly, adding the name of your component: components: products: - filename: your-component-name.owl 3) Add the component to your catalog file (src/ontology/catalog-v001.xml) <uri name=\"https://w3id.org/pmd/co/pmdco/components/your-component-name.owl\" uri=\"components/your-component-name.owl\"/> 4) Add the component to the edit file (src/ontology/pmdco-edit.obo) for .obo formats: import: https://w3id.org/pmd/co/pmdco/components/your-component-name.owl for .owl formats: Import(<https://w3id.org/pmd/co/pmdco/components/your-component-name.owl>) 5) Refresh your repo by running sh run.sh make update_repo - this should create a new file in src/ontology/components. 6) In your custom makefile (src/ontology/pmdco.Makefile) add a goal for your custom make file. In this example, the goal is a ROBOT template. $(COMPONENTSDIR)/your-component-name.owl: $(SRC) ../templates/your-component-template.tsv $(ROBOT) template --template ../templates/your-component-template.tsv \\ annotate --ontology-iri $(ONTBASE)/$@ --output $(COMPONENTSDIR)/your-component-name.owl (If using a ROBOT template, do not forget to add your template tsv in src/templates/) 7) Make the file by running sh run.sh make components/your-component-name.owl","title":"Adding components to an ODK repo"},{"location":"odk-workflows/components/#adding-components-to-an-odk-repo","text":"For details on what components are, please see component section of repository file structure document . To add custom components to an ODK repo, please follow the following steps: 1) Locate your odk yaml file and open it with your favourite text editor (src/ontology/pmdco-odk.yaml) 2) Search if there is already a component section to the yaml file, if not add it accordingly, adding the name of your component: components: products: - filename: your-component-name.owl 3) Add the component to your catalog file (src/ontology/catalog-v001.xml) <uri name=\"https://w3id.org/pmd/co/pmdco/components/your-component-name.owl\" uri=\"components/your-component-name.owl\"/> 4) Add the component to the edit file (src/ontology/pmdco-edit.obo) for .obo formats: import: https://w3id.org/pmd/co/pmdco/components/your-component-name.owl for .owl formats: Import(<https://w3id.org/pmd/co/pmdco/components/your-component-name.owl>) 5) Refresh your repo by running sh run.sh make update_repo - this should create a new file in src/ontology/components. 6) In your custom makefile (src/ontology/pmdco.Makefile) add a goal for your custom make file. In this example, the goal is a ROBOT template. $(COMPONENTSDIR)/your-component-name.owl: $(SRC) ../templates/your-component-template.tsv $(ROBOT) template --template ../templates/your-component-template.tsv \\ annotate --ontology-iri $(ONTBASE)/$@ --output $(COMPONENTSDIR)/your-component-name.owl (If using a ROBOT template, do not forget to add your template tsv in src/templates/) 7) Make the file by running sh run.sh make components/your-component-name.owl","title":"Adding components to an ODK repo"}]}